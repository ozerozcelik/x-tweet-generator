"""
X Algorithm-Based Tweet Generator
Based on: https://github.com/xai-org/x-algorithm

Bu tool, X'in For You algoritmasÄ±nÄ±n puanlama sistemine gÃ¶re
tweet'lerinizi optimize etmenize yardÄ±mcÄ± olur.

AI-powered yaratÄ±cÄ± tweet Ã¼retimi iÃ§in Claude API kullanÄ±r.
"""

import re
import json
import random
import os
import urllib.request
import urllib.error
import ssl
from dataclasses import dataclass
from typing import List, Dict, Optional
from enum import Enum

# SSL context for HTTPS requests (ignore certificate errors)
SSL_CONTEXT = ssl.create_default_context()
SSL_CONTEXT.check_hostname = False
SSL_CONTEXT.verify_mode = ssl.CERT_NONE

# Claude API iÃ§in
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

# X API iÃ§in
try:
    import tweepy
    TWEEPY_AVAILABLE = True
except ImportError:
    TWEEPY_AVAILABLE = False

# Requests kÃ¼tÃ¼phanesi (daha gÃ¼venilir HTTP client)
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False

# ntscraper kÃ¼tÃ¼phanesi (Nitter tabanlÄ± scraper)
try:
    from ntscraper import Nitter
    NTSCRAPER_AVAILABLE = True
except ImportError:
    NTSCRAPER_AVAILABLE = False


class ActionType(Enum):
    """X algoritmasÄ±nÄ±n tahmin ettiÄŸi 15 eylem tÃ¼rÃ¼"""
    FAVORITE = "favorite"
    REPLY = "reply"
    REPOST = "repost"
    QUOTE = "quote"
    CLICK = "click"
    PROFILE_CLICK = "profile_click"
    VIDEO_VIEW = "video_view"
    PHOTO_EXPAND = "photo_expand"
    SHARE = "share"
    DWELL = "dwell"
    FOLLOW_AUTHOR = "follow_author"
    NOT_INTERESTED = "not_interested"
    BLOCK_AUTHOR = "block_author"
    MUTE_AUTHOR = "mute_author"
    REPORT = "report"


# ============================================================================
# X ALGORÄ°TMASI AÄžIRLIKLARI (Rust codebase analizi - Ocak 2025)
# Kaynak: Phoenix WeightedScorer, AuthorDiversityScorer, OONScorer
# ============================================================================

# Pozitif Sinyaller - Engagement aksiyonlarÄ±
ACTION_WEIGHTS = {
    # Core engagement (yÃ¼ksek deÄŸerli)
    ActionType.FAVORITE: 0.5,           # ServerTweetFav
    ActionType.REPLY: 1.0,              # ServerTweetReply - YÃ¼ksek deÄŸer (conversation starter)
    ActionType.REPOST: 1.0,             # ServerTweetRetweet
    ActionType.QUOTE: 1.0,              # ServerTweetQuote - En deÄŸerli (orijinal iÃ§erik + amplification)

    # Click aksiyonlarÄ± (orta deÄŸer)
    ActionType.CLICK: 0.5,              # ClientTweetClick
    ActionType.PROFILE_CLICK: 1.0,      # ClientTweetClickProfile - YÃ¼ksek (discovery)
    ActionType.PHOTO_EXPAND: 0.5,       # ClientTweetPhotoExpand

    # Video aksiyonlarÄ±
    ActionType.VIDEO_VIEW: 0.3,         # ClientTweetVideoQualityView (VQV) - sadece uzun videolar iÃ§in

    # Share aksiyonlarÄ± (en deÄŸerli - off-platform amplification)
    ActionType.SHARE: 1.0,              # ClientTweetShare
    ActionType.DWELL: 0.25,             # ClientTweetRecapDwelled (kÄ±sa okuma)

    # Follow - en yÃ¼ksek deÄŸer
    ActionType.FOLLOW_AUTHOR: 4.0,      # ClientTweetFollowAuthor - Critical signal

    # Negatif sinyaller (skoru dÃ¼ÅŸÃ¼rÃ¼r)
    ActionType.NOT_INTERESTED: -1.0,    # ClientTweetNotInterestedIn
    ActionType.BLOCK_AUTHOR: -1.0,      # ClientTweetBlockAuthor
    ActionType.MUTE_AUTHOR: -1.0,       # ClientTweetMuteAuthor
    ActionType.REPORT: -1.0,            # ClientTweetReport
}

# GeniÅŸletilmiÅŸ aÄŸÄ±rlÄ±klar (ek sinyaller)
EXTENDED_WEIGHTS = {
    "share_via_dm": 1.5,                # DM ile paylaÅŸÄ±m - Ã§ok deÄŸerli (private recommendation)
    "share_via_copy_link": 1.0,         # Link kopyalama - off-platform share
    "quoted_click": 0.5,                # Quote tweet'e tÄ±klama
    "dwell_time_continuous": 0.1,       # Saniye baÅŸÄ±na dwell time bonus
    "bookmark": 1.0,                    # Bookmark (tahmini)
}

# Author Diversity Scorer parametreleri
AUTHOR_DIVERSITY_DECAY = 0.5           # Her tekrar eden yazar iÃ§in %50 decay
AUTHOR_DIVERSITY_FLOOR = 0.1           # Minimum multiplier (asla 0'a dÃ¼ÅŸmez)

# Out-of-Network (OON) adjustment
OON_WEIGHT_FACTOR = 0.8                # Takip etmediÄŸin kiÅŸilerin tweetleri %20 penalty

# Negative score offset (negatif skorlarÄ± normalize etmek iÃ§in)
NEGATIVE_SCORES_OFFSET = 1.0

# X Premium karakter limiti
MAX_CHARS_STANDARD = 280
MAX_CHARS_PREMIUM = 25000

# TweetCred Skoru Sabitleri (Jack'in geliÅŸtirdiÄŸi otorite skalasÄ±)
TWEETCRED_DEFAULT = -128  # Her hesap buradan baÅŸlar
TWEETCRED_VERIFIED_BOOST = 100  # Mavi tik +100 puan
TWEETCRED_MIN_POSITIVE = 17  # Bu skora ulaÅŸmadan eriÅŸim neredeyse sÄ±fÄ±r
TWEETCRED_COLD_START_THRESHOLD = -50  # Bu skorun altÄ±nda cold start suppression

# Engagement Debt Sabitleri
ENGAGEMENT_DEBT_THRESHOLD = 0.005  # %0.5 like/impression oranÄ±
COLD_START_DISTRIBUTION = 0.10  # %10 daÄŸÄ±tÄ±m (cold start suppression aktifken)

# Dwell Time Sabitleri
DWELL_TIME_MIN_SECONDS = 3  # 3 saniyeden az = negatif sinyal
DWELL_TIME_QUALITY_PENALTY = 0.15  # %15-20 quality multiplier dÃ¼ÅŸÃ¼ÅŸÃ¼

# TÃ¼rkiye Reklam NiÅŸleri (yerli markalar)
TR_PROFITABLE_NICHES = [
    "finans", "banka", "borsa", "kripto", "yatÄ±rÄ±m",
    "bahis", "iddia", "casino",
    "e-ticaret", "pazaryeri", "alÄ±ÅŸveriÅŸ",
    "teknoloji", "yazÄ±lÄ±m", "startup"
]

# Global KarlÄ± NiÅŸler (US/EU reklamverenler)
GLOBAL_PROFITABLE_NICHES = [
    "crypto", "trading", "forex", "stocks", "investment",
    "saas", "tech", "ai", "fintech",
    "marketing", "business", "entrepreneurship"
]

# ============================================================================
# TWEET ZAMANLAMA OPTÄ°MÄ°ZASYONU (Twitter Analytics verilerine dayalÄ±)
# ============================================================================

# Saat bazlÄ± engagement multiplier (UTC+3 TÃ¼rkiye saati)
# 1.0 = ortalama, >1.0 = yÃ¼ksek engagement, <1.0 = dÃ¼ÅŸÃ¼k engagement
HOURLY_ENGAGEMENT_MULTIPLIERS = {
    0: 0.4,   # 00:00 - Gece yarÄ±sÄ± (Ã§ok dÃ¼ÅŸÃ¼k)
    1: 0.3,   # 01:00
    2: 0.2,   # 02:00
    3: 0.2,   # 03:00
    4: 0.2,   # 04:00
    5: 0.3,   # 05:00
    6: 0.5,   # 06:00 - Sabah uyanÄ±ÅŸ
    7: 0.7,   # 07:00
    8: 0.9,   # 08:00 - Ä°ÅŸ baÅŸlangÄ±cÄ±
    9: 1.1,   # 09:00 - Prime time baÅŸlangÄ±cÄ±
    10: 1.2,  # 10:00
    11: 1.3,  # 11:00 - Ã–ÄŸle Ã¶ncesi peak
    12: 1.4,  # 12:00 - Ã–ÄžLE PEAK
    13: 1.3,  # 13:00
    14: 1.1,  # 14:00
    15: 1.0,  # 15:00
    16: 1.0,  # 16:00
    17: 1.1,  # 17:00 - Ä°ÅŸ Ã§Ä±kÄ±ÅŸÄ±
    18: 1.3,  # 18:00 - AKÅžAM PEAK
    19: 1.4,  # 19:00 - EN YÃœKSEK
    20: 1.3,  # 20:00
    21: 1.2,  # 21:00
    22: 0.9,  # 22:00
    23: 0.6,  # 23:00
}

# GÃ¼n bazlÄ± engagement multiplier
# Pazartesi=0, Pazar=6
DAILY_ENGAGEMENT_MULTIPLIERS = {
    0: 0.9,   # Pazartesi - Hafta baÅŸÄ± yoÄŸunluÄŸu
    1: 1.0,   # SalÄ± - Normal
    2: 1.1,   # Ã‡arÅŸamba - Peak gÃ¼n
    3: 1.1,   # PerÅŸembe - Peak gÃ¼n
    4: 1.0,   # Cuma - Hafta sonu Ã¶ncesi
    5: 0.8,   # Cumartesi - DÃ¼ÅŸÃ¼k
    6: 0.7,   # Pazar - En dÃ¼ÅŸÃ¼k
}

# Tweet iÃ§erik tipi multiplier'larÄ±
CONTENT_TYPE_MULTIPLIERS = {
    "text_only": 1.0,           # Sadece metin
    "with_image": 1.5,          # GÃ¶rsel iÃ§erik +50%
    "with_video": 2.0,          # Video iÃ§erik +100%
    "with_poll": 1.8,           # Anket +80%
    "with_link": 0.8,           # Harici link -20% (Twitter linki sevmez)
    "thread": 1.3,              # Thread +30%
    "reply": 0.6,               # Reply dÃ¼ÅŸÃ¼k reach
    "quote": 1.2,               # Quote tweet +20%
}

# Optimal posting saatleri (TÃ¼rkiye iÃ§in)
OPTIMAL_POSTING_HOURS_TR = [
    {"hour": 12, "day_range": "weekday", "description": "Ã–ÄŸle molasÄ±", "score": 95},
    {"hour": 19, "day_range": "weekday", "description": "AkÅŸam prime time", "score": 100},
    {"hour": 9, "day_range": "weekday", "description": "Ä°ÅŸ baÅŸlangÄ±cÄ±", "score": 85},
    {"hour": 18, "day_range": "weekday", "description": "Ä°ÅŸ Ã§Ä±kÄ±ÅŸÄ±", "score": 90},
    {"hour": 21, "day_range": "all", "description": "Gece scrolling", "score": 80},
    {"hour": 11, "day_range": "weekend", "description": "Hafta sonu brunch", "score": 75},
]

# Viral potansiyel faktÃ¶rleri
VIRAL_FACTORS = {
    "controversial_topic": 2.5,    # TartÄ±ÅŸmalÄ± konu
    "breaking_news": 3.0,          # Son dakika haberi
    "trending_hashtag": 2.0,       # Trend hashtag kullanÄ±mÄ±
    "celebrity_mention": 2.0,      # ÃœnlÃ¼ mention
    "humor": 1.8,                  # Mizah iÃ§erik
    "relatable": 1.5,              # Ä°liÅŸkilendirilebilir iÃ§erik
    "educational": 1.3,            # EÄŸitici iÃ§erik
    "personal_story": 1.4,         # KiÅŸisel hikaye
}


@dataclass
class TweetAnalysis:
    """Tweet analiz sonucu"""
    score: float
    strengths: List[str]
    weaknesses: List[str]
    suggestions: List[str]
    engagement_prediction: Dict[str, float]
    profile_boost: float = 1.0  # Profil bazlÄ± Ã§arpan


@dataclass
class XProfile:
    """X Profil bilgileri"""
    username: str
    name: str
    followers_count: int
    following_count: int
    tweet_count: int
    created_at: str
    verified: bool
    description: str
    profile_image_url: str = ""

    @property
    def account_age_days(self) -> int:
        """Hesap yaÅŸÄ±nÄ± gÃ¼n olarak hesapla"""
        from datetime import datetime
        try:
            created = datetime.strptime(self.created_at, "%Y-%m-%dT%H:%M:%S.%fZ")
            return (datetime.now() - created).days
        except:
            return 0

    @property
    def follower_ratio(self) -> float:
        """TakipÃ§i/Takip oranÄ±"""
        if self.following_count == 0:
            return self.followers_count
        return self.followers_count / self.following_count

    @property
    def engagement_tier(self) -> str:
        """Hesap seviyesi"""
        if self.followers_count >= 1000000:
            return "mega"  # 1M+
        elif self.followers_count >= 100000:
            return "macro"  # 100K+
        elif self.followers_count >= 10000:
            return "mid"  # 10K+
        elif self.followers_count >= 1000:
            return "micro"  # 1K+
        elif self.followers_count >= 100:
            return "nano"  # 100+
        else:
            return "starter"  # <100


@dataclass
class TweetCredScore:
    """
    TweetCred Skoru - Jack'in geliÅŸtirdiÄŸi hesap otorite skalasÄ±

    Her hesap -128'den baÅŸlar.
    Minimum +17'ye ulaÅŸmadan eriÅŸim gÃ¼cÃ¼ neredeyse sÄ±fÄ±r.
    Verified hesaplar +100 boost alÄ±r (-28'den baÅŸlar).
    """
    base_score: int = TWEETCRED_DEFAULT
    verified_boost: int = 0
    bio_score: int = 0
    ratio_score: int = 0
    language_score: int = 0
    engagement_history_score: int = 0
    niche_focus_score: int = 0

    @property
    def total_score(self) -> int:
        """Toplam TweetCred skoru"""
        return (
            self.base_score +
            self.verified_boost +
            self.bio_score +
            self.ratio_score +
            self.language_score +
            self.engagement_history_score +
            self.niche_focus_score
        )

    @property
    def is_positive(self) -> bool:
        """Skor pozitif mi?"""
        return self.total_score >= TWEETCRED_MIN_POSITIVE

    @property
    def has_cold_start_suppression(self) -> bool:
        """Cold start suppression aktif mi?"""
        return self.total_score <= TWEETCRED_COLD_START_THRESHOLD

    @property
    def distribution_rate(self) -> float:
        """Post daÄŸÄ±tÄ±m oranÄ±"""
        if self.has_cold_start_suppression:
            return COLD_START_DISTRIBUTION  # %10
        elif not self.is_positive:
            return 0.3  # %30
        elif self.total_score >= 50:
            return 1.0  # %100
        else:
            return 0.5 + (self.total_score / 100)  # %50-100 arasÄ±


@dataclass
class EngagementDebt:
    """
    Engagement Debt - Algoritmik BorÃ§ Sistemi

    Ä°lk 100 post'ta %0.5'ten dÃ¼ÅŸÃ¼k like/impression oranÄ± varsa,
    skor kalÄ±cÄ± olarak -50'ye kadar dÃ¼ÅŸebilir ve
    "cold start suppression" modunu tetikler.
    """
    total_posts: int = 0
    total_likes: int = 0
    total_impressions: int = 0
    debt_level: float = 0.0  # 0-1 arasÄ±, 1 = maksimum borÃ§

    @property
    def engagement_rate(self) -> float:
        """Like/Impression oranÄ±"""
        if self.total_impressions == 0:
            return 0.0
        return self.total_likes / self.total_impressions

    @property
    def has_debt(self) -> bool:
        """Engagement borcu var mÄ±?"""
        return (
            self.total_posts >= 10 and
            self.engagement_rate < ENGAGEMENT_DEBT_THRESHOLD
        )

    @property
    def severity(self) -> str:
        """BorÃ§ ÅŸiddeti"""
        if not self.has_debt:
            return "none"
        rate = self.engagement_rate
        if rate < 0.001:
            return "critical"  # %0.1'in altÄ±
        elif rate < 0.003:
            return "severe"  # %0.3'Ã¼n altÄ±
        else:
            return "moderate"  # %0.5'in altÄ±


@dataclass
class MonetizationAnalysis:
    """X'den para kazanma analizi"""
    estimated_rpm: float  # Revenue per mille (1000 gÃ¶rÃ¼ntÃ¼lenme baÅŸÄ±na gelir)
    niche_profitability: str  # low, medium, high
    target_market: str  # TR, EU, US, Global
    recommended_niches: List[str]
    warnings: List[str]
    tips: List[str]


class TweetCredAnalyzer:
    """
    TweetCred ve Engagement Debt Analizi

    X algoritmasÄ±nÄ±n gizli otorite skorlama sistemini simÃ¼le eder.
    """

    def calculate_tweetcred(
        self,
        profile: XProfile,
        avg_engagement_rate: float = 0.02,
        post_consistency: float = 0.5,
        niche_focus: float = 0.5
    ) -> TweetCredScore:
        """
        TweetCred skorunu hesaplar.

        Args:
            profile: X profil bilgileri
            avg_engagement_rate: Ortalama engagement oranÄ±
            post_consistency: Post tutarlÄ±lÄ±ÄŸÄ± (0-1)
            niche_focus: NiÅŸ odaklanma (0-1)

        Returns:
            TweetCredScore objesi
        """
        score = TweetCredScore()

        # Verified boost
        if profile.verified:
            score.verified_boost = TWEETCRED_VERIFIED_BOOST

        # Bio skoru (dolu ve kaliteli bio)
        if profile.description:
            bio_len = len(profile.description)
            if bio_len >= 100:
                score.bio_score = 15
            elif bio_len >= 50:
                score.bio_score = 10
            elif bio_len >= 20:
                score.bio_score = 5

        # Takip/TakipÃ§i ratio skoru
        ratio = profile.follower_ratio
        if ratio >= 10:
            score.ratio_score = 30
        elif ratio >= 5:
            score.ratio_score = 20
        elif ratio >= 2:
            score.ratio_score = 15
        elif ratio >= 1:
            score.ratio_score = 10
        elif ratio >= 0.5:
            score.ratio_score = 5
        else:
            score.ratio_score = -10  # Ã‡ok dÃ¼ÅŸÃ¼k ratio penaltÄ±

        # Engagement history skoru
        if avg_engagement_rate >= 0.05:
            score.engagement_history_score = 40
        elif avg_engagement_rate >= 0.03:
            score.engagement_history_score = 30
        elif avg_engagement_rate >= 0.02:
            score.engagement_history_score = 20
        elif avg_engagement_rate >= 0.01:
            score.engagement_history_score = 10
        elif avg_engagement_rate >= 0.005:
            score.engagement_history_score = 0
        else:
            score.engagement_history_score = -20  # DÃ¼ÅŸÃ¼k engagement penaltÄ±

        # NiÅŸ odaklanma skoru
        score.niche_focus_score = int(niche_focus * 30)

        # Hesap yaÅŸÄ± bonusu
        age_days = profile.account_age_days
        if age_days >= 365 * 3:  # 3+ yÄ±l
            score.engagement_history_score += 15
        elif age_days >= 365:  # 1+ yÄ±l
            score.engagement_history_score += 10
        elif age_days >= 180:  # 6+ ay
            score.engagement_history_score += 5

        return score

    def analyze_engagement_debt(
        self,
        posts: int,
        likes: int,
        impressions: int
    ) -> EngagementDebt:
        """
        Engagement debt analizi yapar.

        Args:
            posts: Toplam post sayÄ±sÄ±
            likes: Toplam beÄŸeni sayÄ±sÄ±
            impressions: Toplam gÃ¶rÃ¼ntÃ¼lenme sayÄ±sÄ±

        Returns:
            EngagementDebt objesi
        """
        debt = EngagementDebt(
            total_posts=posts,
            total_likes=likes,
            total_impressions=impressions
        )

        if debt.has_debt:
            # BorÃ§ seviyesini hesapla
            rate = debt.engagement_rate
            if rate < 0.001:
                debt.debt_level = 1.0
            elif rate < 0.003:
                debt.debt_level = 0.7
            else:
                debt.debt_level = 0.4

        return debt

    def get_monetization_analysis(
        self,
        profile: XProfile,
        niche: str,
        target_market: str = "TR"
    ) -> MonetizationAnalysis:
        """
        Monetization analizi yapar.

        Args:
            profile: Profil bilgileri
            niche: Ä°Ã§erik niÅŸi
            target_market: Hedef pazar (TR, EU, US)

        Returns:
            MonetizationAnalysis objesi
        """
        warnings = []
        tips = []
        recommended_niches = []

        niche_lower = niche.lower()

        # RPM tahmini (1000 gÃ¶rÃ¼ntÃ¼lenme baÅŸÄ±na gelir)
        base_rpm = 0.5  # Base RPM (USD)

        # Market Ã§arpanÄ±
        market_multiplier = {
            "US": 3.0,
            "EU": 2.0,
            "TR": 0.3,  # Tier 3 Ã¼lke
            "Global": 1.5
        }.get(target_market, 1.0)

        # NiÅŸ Ã§arpanÄ±
        if any(n in niche_lower for n in ["crypto", "kripto", "borsa", "trading", "forex"]):
            niche_multiplier = 3.0
            niche_profitability = "high"
        elif any(n in niche_lower for n in ["finans", "banka", "yatÄ±rÄ±m", "fintech"]):
            niche_multiplier = 2.5
            niche_profitability = "high"
        elif any(n in niche_lower for n in ["bahis", "iddia", "casino"]):
            niche_multiplier = 2.0
            niche_profitability = "medium-high"
        elif any(n in niche_lower for n in ["tech", "yazÄ±lÄ±m", "ai", "startup"]):
            niche_multiplier = 1.5
            niche_profitability = "medium"
        elif any(n in niche_lower for n in ["e-ticaret", "pazaryeri", "alÄ±ÅŸveriÅŸ"]):
            niche_multiplier = 1.3
            niche_profitability = "medium"
        else:
            niche_multiplier = 0.8
            niche_profitability = "low"

        # Verified Ã§arpanÄ±
        verified_multiplier = 1.3 if profile.verified else 1.0

        # Final RPM
        estimated_rpm = base_rpm * market_multiplier * niche_multiplier * verified_multiplier

        # UyarÄ±lar
        if target_market == "TR":
            warnings.append("TÃ¼rkiye tier 3 Ã¼lke - RPM dÃ¼ÅŸÃ¼k")
            warnings.append("Yerli markalarÄ±n reklam verdiÄŸi niÅŸlere odaklan")
            recommended_niches = TR_PROFITABLE_NICHES[:5]
            tips.append("Finans, borsa, kripto niÅŸlerinde iÃ§erik Ã¼ret")
            tips.append("Bahis/iddia platformlarÄ± TR'de yÃ¼ksek reklam bÃ¼tÃ§esi harcÄ±yor")

        if target_market in ["US", "EU"]:
            tips.append("Mention farm yapan hesaplar gibi strateji izle (@cb_doge Ã¶rneÄŸi)")
            tips.append("Ä°ngilizce iÃ§erik = daha yÃ¼ksek RPM")
            recommended_niches = GLOBAL_PROFITABLE_NICHES[:5]

        if not profile.verified:
            warnings.append("Mavi tik olmadan gelir potansiyeli sÄ±nÄ±rlÄ±")
            tips.append("X Premium al - duplicate content detector'den %30 muafiyet")

        # Genel tavsiyeler
        tips.append("Mention'lara Ã§ekmeye odaklan - asÄ±l gelir oradan")
        tips.append("Dwell time'Ä± artÄ±r - uzun okunabilir iÃ§erik")

        return MonetizationAnalysis(
            estimated_rpm=round(estimated_rpm, 2),
            niche_profitability=niche_profitability,
            target_market=target_market,
            recommended_niches=recommended_niches,
            warnings=warnings,
            tips=tips
        )

    def get_dwell_time_tips(self, tweet: str) -> List[str]:
        """Tweet iÃ§in dwell time optimizasyon Ã¶nerileri"""
        tips = []
        lines = tweet.count('\n')
        words = len(tweet.split())

        if words < 30:
            tips.append("Daha uzun iÃ§erik = daha fazla dwell time")

        if lines < 3:
            tips.append("SatÄ±r aralarÄ± ekle - okuma sÃ¼resini artÄ±rÄ±r")

        if '?' not in tweet:
            tips.append("Soru ekle - dÃ¼ÅŸÃ¼nme sÃ¼resi = dwell time")

        if not any(c in tweet for c in ['1.', '2.', 'â€¢', '-', 'â†’']):
            tips.append("Liste formatÄ± kullan - taranabilir iÃ§erik dwell time artÄ±rÄ±r")

        if 'ama' not in tweet.lower() and 'ancak' not in tweet.lower() and 'fakat' not in tweet.lower():
            tips.append("Plot twist/karÅŸÄ±tlÄ±k ekle - merak uyandÄ±rÄ±r")

        return tips


class TweetScraper:
    """
    API gerektirmeden tweet Ã§ekme.
    Birden fazla yÃ¶ntem dener: Syndication API, xcancel, Nitter alternatifleri.
    """

    # Ã‡alÄ±ÅŸan alternatif instance'lar (Ocak 2025 gÃ¼ncel)
    # xcancel.com en gÃ¼venilir, diÄŸerleri yedek
    ALTERNATIVE_INSTANCES = [
        "xcancel.com",
        "twiiit.com",
        "nitter.privacydev.net",
        "nitter.poast.org",
    ]

    def __init__(self):
        self.working_instance = None
        self.working_method = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }

    def _decompress_response(self, response) -> str:
        """Response'u decompress et (gzip desteÄŸi)"""
        import gzip
        import io

        data = response.read()
        if response.info().get('Content-Encoding') == 'gzip':
            try:
                buf = io.BytesIO(data)
                with gzip.GzipFile(fileobj=buf) as f:
                    return f.read().decode('utf-8')
            except:
                pass
        return data.decode('utf-8', errors='ignore')

    def fetch_tweets_syndication(self, username: str, count: int = 50) -> List[Dict]:
        """
        Twitter Syndication API uzerinden tweet cek.
        Bu API herkese acik ve API key gerektirmiyor.
        """
        tweets = []
        try:
            # Twitter'in embed/syndication endpoint'i
            url = f"https://syndication.twitter.com/srv/timeline-profile/screen-name/{username}"

            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Referer': 'https://twitter.com/',
                'Origin': 'https://twitter.com',
            }

            html = None

            # Requests kutuphanesi varsa onu kullan (daha guvenilir)
            if REQUESTS_AVAILABLE:
                try:
                    print(f"[Syndication] Fetching {url}")
                    resp = requests.get(url, headers=headers, timeout=30, verify=False)
                    print(f"[Syndication] Response status: {resp.status_code}, length: {len(resp.text)}")
                    resp.raise_for_status()
                    html = resp.text
                except Exception as req_err:
                    print(f"[Syndication] Requests failed: {req_err}")
                    # urllib fallback
                    try:
                        req = urllib.request.Request(url, headers=headers)
                        with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                            html = self._decompress_response(response)
                            print(f"[Syndication] urllib fallback success, length: {len(html)}")
                    except Exception as urllib_err:
                        print(f"[Syndication] urllib also failed: {urllib_err}")
            else:
                req = urllib.request.Request(url, headers=headers)
                with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                    html = self._decompress_response(response)
                    print(f"[Syndication] urllib success, length: {len(html)}")

            if not html:
                print("[Syndication] No HTML received")
                return []

            # JSON data'yi HTML icinden cikar
            # Syndication API HTML icinde JSON embed eder
            json_pattern = r'<script[^>]*id="__NEXT_DATA__"[^>]*>(.*?)</script>'
            json_match = re.search(json_pattern, html, re.DOTALL)

            if json_match:
                print(f"[Syndication] Found __NEXT_DATA__ script tag")
                try:
                    data = json.loads(json_match.group(1))
                    timeline = data.get('props', {}).get('pageProps', {}).get('timeline', {})
                    entries = timeline.get('entries', [])
                    print(f"[Syndication] Found {len(entries)} entries in timeline")

                    for entry in entries[:count]:
                        content = entry.get('content', {})
                        tweet_data = content.get('tweet', {})

                        if tweet_data:
                            text = tweet_data.get('full_text', tweet_data.get('text', ''))
                            if text and len(text) > 10:
                                tweets.append({
                                    "text": text,
                                    "likes": tweet_data.get('favorite_count', 0),
                                    "retweets": tweet_data.get('retweet_count', 0),
                                    "replies": tweet_data.get('reply_count', 0),
                                    "impressions": tweet_data.get('view_count', 100)
                                })
                    print(f"[Syndication] Parsed {len(tweets)} tweets from JSON")
                except json.JSONDecodeError as je:
                    print(f"[Syndication] JSON decode error: {je}")
            else:
                print(f"[Syndication] No __NEXT_DATA__ found, trying alternative patterns")

            # Alternatif: HTML'den direkt parse et
            if not tweets:
                # Tweet text pattern
                tweet_pattern = r'data-tweet-id="[^"]*"[^>]*>.*?<p[^>]*class="[^"]*tweet-text[^"]*"[^>]*>(.*?)</p>'
                matches = re.findall(tweet_pattern, html, re.DOTALL | re.IGNORECASE)

                for match in matches[:count]:
                    text = re.sub(r'<[^>]+>', '', match)
                    text = text.strip()
                    if text and len(text) > 10:
                        tweets.append({
                            "text": text,
                            "likes": 0,
                            "retweets": 0,
                            "replies": 0,
                            "impressions": 100
                        })

            if tweets:
                self.working_method = "Syndication API"

        except Exception as e:
            print(f"Syndication API error: {e}")

        return tweets

    def _find_working_instance(self) -> Optional[str]:
        """Ã‡alÄ±ÅŸan bir alternatif instance bul"""
        for instance in self.ALTERNATIVE_INSTANCES:
            try:
                url = f"https://{instance}/"
                req = urllib.request.Request(url, headers=self.headers)
                with urllib.request.urlopen(req, timeout=8, context=SSL_CONTEXT) as response:
                    if response.status == 200:
                        self.working_instance = instance
                        return instance
            except Exception as e:
                print(f"Instance {instance} failed: {e}")
                continue
        return None

    def fetch_tweets_xcancel(self, username: str, count: int = 50) -> List[Dict]:
        """
        xcancel.com Ã¼zerinden tweet Ã§ek (en gÃ¼venilir Nitter alternatifi).
        """
        tweets = []
        try:
            url = f"https://xcancel.com/{username}"

            # Requests kÃ¼tÃ¼phanesi varsa onu kullan
            if REQUESTS_AVAILABLE:
                try:
                    resp = requests.get(url, headers=self.headers, timeout=20, verify=False)
                    resp.raise_for_status()
                    html = resp.text
                except Exception as req_err:
                    print(f"xcancel requests failed: {req_err}")
                    req = urllib.request.Request(url, headers=self.headers)
                    with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                        html = self._decompress_response(response)
            else:
                req = urllib.request.Request(url, headers=self.headers)
                with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                    html = self._decompress_response(response)

            # xcancel Nitter tabanlÄ±, aynÄ± HTML yapÄ±sÄ±nÄ± kullanÄ±yor
            tweet_pattern = r'<div class="tweet-content[^"]*"[^>]*>(.*?)</div>'
            matches = re.findall(tweet_pattern, html, re.DOTALL)

            for match in matches[:count]:
                text = re.sub(r'<[^>]+>', '', match)
                text = text.strip()

                if text and len(text) > 10:
                    tweets.append({
                        "text": text,
                        "likes": 0,
                        "retweets": 0,
                        "replies": 0,
                        "impressions": 100
                    })

            if tweets:
                self.working_method = "xcancel.com"

        except Exception as e:
            print(f"xcancel fetch error: {e}")

        return tweets

    def fetch_tweets_nitter(self, username: str, count: int = 50) -> List[Dict]:
        """
        Nitter alternatifleri Ã¼zerinden tweet Ã§ek.
        """
        if not self.working_instance:
            self._find_working_instance()

        if not self.working_instance:
            return []

        tweets = []
        try:
            url = f"https://{self.working_instance}/{username}"
            req = urllib.request.Request(url, headers=self.headers)

            with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                html = self._decompress_response(response)

            # Tweet iÃ§eriklerini bul
            tweet_pattern = r'<div class="tweet-content[^"]*"[^>]*>(.*?)</div>'
            matches = re.findall(tweet_pattern, html, re.DOTALL)

            for match in matches[:count]:
                text = re.sub(r'<[^>]+>', '', match)
                text = text.strip()

                if text and len(text) > 10:
                    tweets.append({
                        "text": text,
                        "likes": 0,
                        "retweets": 0,
                        "replies": 0,
                        "impressions": 100
                    })

            if tweets:
                self.working_method = f"Nitter ({self.working_instance})"

        except Exception as e:
            print(f"Nitter fetch error: {e}")

        return tweets

    def fetch_tweets_rss(self, username: str, count: int = 50) -> List[Dict]:
        """
        RSS feed Ã¼zerinden tweet Ã§ek.
        """
        # Ã–nce xcancel RSS dene
        rss_sources = [
            f"https://xcancel.com/{username}/rss",
        ]

        if self.working_instance:
            rss_sources.append(f"https://{self.working_instance}/{username}/rss")

        tweets = []
        for rss_url in rss_sources:
            try:
                req = urllib.request.Request(rss_url, headers=self.headers)

                with urllib.request.urlopen(req, timeout=15, context=SSL_CONTEXT) as response:
                    xml = self._decompress_response(response)

                # RSS parsing
                item_pattern = r'<item>(.*?)</item>'
                items = re.findall(item_pattern, xml, re.DOTALL)

                for item in items[:count]:
                    desc_match = re.search(r'<description>(.*?)</description>', item, re.DOTALL)
                    if desc_match:
                        text = desc_match.group(1)
                        text = re.sub(r'<!\[CDATA\[', '', text)
                        text = re.sub(r'\]\]>', '', text)
                        text = re.sub(r'<[^>]+>', '', text)
                        text = text.strip()

                        if text and len(text) > 10:
                            tweets.append({
                                "text": text,
                                "likes": 0,
                                "retweets": 0,
                                "replies": 0,
                                "impressions": 100
                            })

                if tweets:
                    self.working_method = "RSS Feed"
                    break

            except Exception as e:
                print(f"RSS fetch error ({rss_url}): {e}")
                continue

        return tweets

    def fetch_tweets_ntscraper(self, username: str, count: int = 50) -> List[Dict]:
        """
        ntscraper kÃ¼tÃ¼phanesi ile tweet Ã§ek.
        Nitter instance'larÄ±nÄ± otomatik yÃ¶netir.
        """
        if not NTSCRAPER_AVAILABLE:
            return []

        tweets = []
        try:
            # ntscraper instance'Ä± oluÅŸtur
            scraper = Nitter(log_level=0, skip_instance_check=False)

            # Profil tweetlerini Ã§ek
            result = scraper.get_tweets(username, mode='user', number=count)

            if result and 'tweets' in result:
                for tweet in result['tweets'][:count]:
                    text = tweet.get('text', '')
                    if text and len(text) > 10:
                        tweets.append({
                            "text": text,
                            "likes": tweet.get('stats', {}).get('likes', 0),
                            "retweets": tweet.get('stats', {}).get('retweets', 0),
                            "replies": tweet.get('stats', {}).get('comments', 0),
                            "impressions": tweet.get('stats', {}).get('likes', 0) * 10 or 100
                        })

            if tweets:
                self.working_method = "ntscraper"

        except Exception as e:
            print(f"ntscraper error: {e}")

        return tweets

    def fetch_tweets(self, username: str, count: int = 50) -> List[Dict]:
        """
        Tweet Ã§ek - birden fazla yÃ¶ntem dener.
        SÄ±ra: Syndication API -> xcancel -> ntscraper -> RSS -> Nitter alternatifleri
        """
        # KullanÄ±cÄ± adÄ±ndan @ iÅŸaretini kaldÄ±r
        username = username.lstrip('@').strip()
        errors = []

        # 1. Ã–nce Twitter Syndication API dene (en gÃ¼venilir)
        print(f"[Scraper] Trying Syndication API for @{username}...")
        try:
            tweets = self.fetch_tweets_syndication(username, count)
            if tweets:
                print(f"[Scraper] [OK] Syndication API: {len(tweets)} tweets found")
                return tweets
            else:
                errors.append("Syndication API: No tweets returned")
        except Exception as e:
            errors.append(f"Syndication API: {str(e)}")
            print(f"[Scraper] Syndication API error: {e}")

        # 2. xcancel.com dene (en gÃ¼venilir Nitter alternatifi)
        print(f"[Scraper] Trying xcancel.com for @{username}...")
        try:
            tweets = self.fetch_tweets_xcancel(username, count)
            if tweets:
                print(f"[Scraper] [OK] xcancel.com: {len(tweets)} tweets found")
                return tweets
            else:
                errors.append("xcancel.com: No tweets returned")
        except Exception as e:
            errors.append(f"xcancel.com: {str(e)}")
            print(f"[Scraper] xcancel.com error: {e}")

        # 3. ntscraper dene (kendi Nitter instance yÃ¶netimi var)
        if NTSCRAPER_AVAILABLE:
            print(f"[Scraper] Trying ntscraper for @{username}...")
            try:
                tweets = self.fetch_tweets_ntscraper(username, count)
                if tweets:
                    print(f"[Scraper] [OK] ntscraper: {len(tweets)} tweets found")
                    return tweets
                else:
                    errors.append("ntscraper: No tweets returned")
            except Exception as e:
                errors.append(f"ntscraper: {str(e)}")
                print(f"[Scraper] ntscraper error: {e}")

        # 4. RSS feed dene
        print(f"[Scraper] Trying RSS feeds for @{username}...")
        try:
            tweets = self.fetch_tweets_rss(username, count)
            if tweets:
                print(f"[Scraper] [OK] RSS: {len(tweets)} tweets found")
                return tweets
            else:
                errors.append("RSS: No tweets returned")
        except Exception as e:
            errors.append(f"RSS: {str(e)}")
            print(f"[Scraper] RSS error: {e}")

        # 5. Son Ã§are: diÄŸer Nitter alternatifleri
        print(f"[Scraper] Trying Nitter alternatives for @{username}...")
        try:
            tweets = self.fetch_tweets_nitter(username, count)
            if tweets:
                print(f"[Scraper] [OK] Nitter: {len(tweets)} tweets found")
                return tweets
            else:
                errors.append("Nitter: No tweets returned")
        except Exception as e:
            errors.append(f"Nitter: {str(e)}")
            print(f"[Scraper] Nitter error: {e}")

        print(f"[Scraper] [FAIL] Could not fetch tweets for @{username}")
        print(f"[Scraper] Errors: {'; '.join(errors)}")
        self.last_errors = errors
        return []

    def get_status(self) -> Dict:
        """Scraper durumunu dÃ¶ndÃ¼r"""
        # TÃ¼m yÃ¶ntemleri test et
        methods_status = []

        # Syndication API test
        try:
            url = "https://syndication.twitter.com/"
            req = urllib.request.Request(url, headers=self.headers)
            with urllib.request.urlopen(req, timeout=5, context=SSL_CONTEXT) as response:
                if response.status == 200:
                    methods_status.append("Syndication API [OK]")
        except:
            methods_status.append("Syndication API [FAIL]")

        # xcancel test
        try:
            url = "https://xcancel.com/"
            req = urllib.request.Request(url, headers=self.headers)
            with urllib.request.urlopen(req, timeout=5, context=SSL_CONTEXT) as response:
                if response.status == 200:
                    methods_status.append("xcancel.com [OK]")
        except:
            methods_status.append("xcancel.com [FAIL]")

        # ntscraper test
        if NTSCRAPER_AVAILABLE:
            try:
                scraper = Nitter(log_level=0, skip_instance_check=True)
                methods_status.append("ntscraper [OK]")
            except:
                methods_status.append("ntscraper [FAIL]")
        else:
            methods_status.append("ntscraper (not installed)")

        # Nitter alternatifleri test
        instance = self._find_working_instance()
        if instance:
            methods_status.append(f"Nitter ({instance}) [OK]")
        else:
            methods_status.append("Nitter alternatifleri [FAIL]")

        working = any("[OK]" in m for m in methods_status)

        return {
            "working": working,
            "instance": self.working_instance,
            "method": self.working_method or "Multiple methods available",
            "methods_status": methods_status
        }


@dataclass
class TweetStyleAnalysis:
    """KullanÄ±cÄ±nÄ±n tweet stil analizi"""
    avg_length: float = 0
    avg_line_breaks: float = 0
    emoji_frequency: float = 0  # emoji per tweet
    question_frequency: float = 0  # soru iÅŸareti kullanan tweet oranÄ±
    hashtag_frequency: float = 0
    mention_frequency: float = 0
    link_frequency: float = 0
    common_words: List[str] = None
    common_emojis: List[str] = None
    tone: str = "neutral"  # professional, casual, provocative, educational
    topics: List[str] = None
    best_performing_patterns: List[str] = None
    avg_engagement_rate: float = 0
    posting_hours: List[int] = None  # en aktif saatler

    def __post_init__(self):
        if self.common_words is None:
            self.common_words = []
        if self.common_emojis is None:
            self.common_emojis = []
        if self.topics is None:
            self.topics = []
        if self.best_performing_patterns is None:
            self.best_performing_patterns = []
        if self.posting_hours is None:
            self.posting_hours = []


class TweetStyleAnalyzer:
    """KullanÄ±cÄ±nÄ±n tweetlerini analiz edip stil Ã§Ä±karÄ±r"""

    EMOJI_PATTERN = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE
    )

    def analyze_tweets(self, tweets: List[Dict]) -> TweetStyleAnalysis:
        """
        Tweet listesini analiz edip stil Ã§Ä±karÄ±r.

        Args:
            tweets: Tweet listesi [{"text": "...", "likes": 10, "retweets": 5, "replies": 2, "impressions": 1000}, ...]

        Returns:
            TweetStyleAnalysis objesi
        """
        if not tweets:
            return TweetStyleAnalysis()

        analysis = TweetStyleAnalysis()

        total_length = 0
        total_line_breaks = 0
        total_emojis = 0
        total_questions = 0
        total_hashtags = 0
        total_mentions = 0
        total_links = 0
        all_emojis = []
        all_words = []
        engagement_rates = []

        for tweet in tweets:
            text = tweet.get("text", "")

            # Uzunluk
            total_length += len(text)

            # SatÄ±r aralarÄ±
            total_line_breaks += text.count('\n')

            # Emojiler
            emojis = self.EMOJI_PATTERN.findall(text)
            total_emojis += len(emojis)
            all_emojis.extend(emojis)

            # Soru iÅŸareti
            if '?' in text:
                total_questions += 1

            # Hashtag
            hashtags = re.findall(r'#\w+', text)
            total_hashtags += len(hashtags)

            # Mention
            mentions = re.findall(r'@\w+', text)
            total_mentions += len(mentions)

            # Link
            if 'http' in text or 't.co' in text:
                total_links += 1

            # Kelimeler (stopword'ler hariÃ§)
            words = re.findall(r'\b[a-zA-ZÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄžÃœÅžÄ°Ã–Ã‡]{4,}\b', text.lower())
            all_words.extend(words)

            # Engagement rate
            impressions = tweet.get("impressions", 0)
            if impressions > 0:
                likes = tweet.get("likes", 0)
                retweets = tweet.get("retweets", 0)
                replies = tweet.get("replies", 0)
                engagement = (likes + retweets * 2 + replies * 1.5) / impressions
                engagement_rates.append(engagement)

        n = len(tweets)

        analysis.avg_length = total_length / n
        analysis.avg_line_breaks = total_line_breaks / n
        analysis.emoji_frequency = total_emojis / n
        analysis.question_frequency = total_questions / n
        analysis.hashtag_frequency = total_hashtags / n
        analysis.mention_frequency = total_mentions / n
        analysis.link_frequency = total_links / n

        # En sÄ±k kullanÄ±lan emojiler
        if all_emojis:
            emoji_counts = {}
            for e in all_emojis:
                emoji_counts[e] = emoji_counts.get(e, 0) + 1
            analysis.common_emojis = sorted(emoji_counts.keys(), key=lambda x: emoji_counts[x], reverse=True)[:5]

        # En sÄ±k kullanÄ±lan kelimeler (stopword'ler hariÃ§)
        stopwords = {'iÃ§in', 'olan', 'gibi', 'daha', 'Ã§ok', 'kadar', 'nasÄ±l', 'neden', 'this', 'that', 'with', 'from', 'have', 'been', 'will', 'your', 'they', 'what', 'when', 'there'}
        filtered_words = [w for w in all_words if w not in stopwords]
        if filtered_words:
            word_counts = {}
            for w in filtered_words:
                word_counts[w] = word_counts.get(w, 0) + 1
            analysis.common_words = sorted(word_counts.keys(), key=lambda x: word_counts[x], reverse=True)[:10]

        # Ortalama engagement
        if engagement_rates:
            analysis.avg_engagement_rate = sum(engagement_rates) / len(engagement_rates)

        # Ton tahmini
        analysis.tone = self._detect_tone(tweets)

        return analysis

    def _detect_tone(self, tweets: List[Dict]) -> str:
        """Tweet'lerden ton tespit et"""
        texts = " ".join([t.get("text", "") for t in tweets]).lower()

        provocative_words = ['tartÄ±ÅŸmalÄ±', 'yanlÄ±ÅŸ', 'hata', 'aslÄ±nda', 'unpopular', 'controversial', 'wrong', 'mistake']
        educational_words = ['Ã¶ÄŸrendim', 'ipucu', 'rehber', 'nasÄ±l', 'adÄ±m', 'learned', 'tips', 'guide', 'how to', 'step']
        casual_words = ['haha', 'lol', 'sjsj', 'random', 'wtf', 'omg']
        professional_words = ['analiz', 'strateji', 'veri', 'rapor', 'analysis', 'strategy', 'data', 'report']

        scores = {
            'provocative': sum(1 for w in provocative_words if w in texts),
            'educational': sum(1 for w in educational_words if w in texts),
            'casual': sum(1 for w in casual_words if w in texts),
            'professional': sum(1 for w in professional_words if w in texts)
        }

        if max(scores.values()) == 0:
            return "neutral"
        return max(scores, key=scores.get)

    def generate_style_prompt(self, analysis: TweetStyleAnalysis) -> str:
        """Stil analizinden AI prompt'u oluÅŸtur"""
        prompt_parts = []

        prompt_parts.append("BU KULLANICININ STÄ°LÄ°NE UYGUN TWEET YAZMALSIN:")

        # Uzunluk
        if analysis.avg_length < 100:
            prompt_parts.append("- KÄ±sa ve Ã¶z tweetler tercih ediyor")
        elif analysis.avg_length < 300:
            prompt_parts.append("- Orta uzunlukta tweetler yazÄ±yor")
        else:
            prompt_parts.append("- Uzun, detaylÄ± tweetler yazÄ±yor")

        # SatÄ±r aralarÄ±
        if analysis.avg_line_breaks >= 2:
            prompt_parts.append("- SatÄ±r aralarÄ± kullanÄ±yor (okunabilirlik iÃ§in)")
        else:
            prompt_parts.append("- Genellikle tek paragraf yazÄ±yor")

        # Emoji
        if analysis.emoji_frequency >= 2:
            prompt_parts.append(f"- Emoji seven biri: {' '.join(analysis.common_emojis[:3]) if analysis.common_emojis else 'ðŸ”¥'}")
        elif analysis.emoji_frequency >= 0.5:
            prompt_parts.append("- Ara sÄ±ra emoji kullanÄ±yor")
        else:
            prompt_parts.append("- Emoji kullanmÄ±yor veya Ã§ok az")

        # Soru
        if analysis.question_frequency >= 0.3:
            prompt_parts.append("- SÄ±klÄ±kla soru soruyor (etkileÅŸim odaklÄ±)")

        # Ton
        tone_desc = {
            'provocative': "- Provokatif ve tartÄ±ÅŸmacÄ± ton",
            'educational': "- EÄŸitici ve bilgi paylaÅŸan ton",
            'casual': "- Rahat ve eÄŸlenceli ton",
            'professional': "- Profesyonel ve ciddi ton",
            'neutral': "- NÃ¶tr ve dengeli ton"
        }
        prompt_parts.append(tone_desc.get(analysis.tone, "- NÃ¶tr ton"))

        # SÄ±k kullanÄ±lan kelimeler
        if analysis.common_words:
            prompt_parts.append(f"- SÄ±k kullandÄ±ÄŸÄ± kelimeler: {', '.join(analysis.common_words[:5])}")

        return "\n".join(prompt_parts)


class XProfileAnalyzer:
    """X Profil analizi ve API entegrasyonu"""

    # TakipÃ§i sayÄ±sÄ±na gÃ¶re engagement Ã§arpanlarÄ±
    TIER_MULTIPLIERS = {
        "mega": 0.5,      # 1M+ - dÃ¼ÅŸÃ¼k engagement rate ama yÃ¼ksek reach
        "macro": 0.7,     # 100K+
        "mid": 1.0,       # 10K+ - optimal
        "micro": 1.3,     # 1K+ - yÃ¼ksek engagement rate
        "nano": 1.5,      # 100+ - Ã§ok yÃ¼ksek engagement
        "starter": 0.8    # <100 - dÃ¼ÅŸÃ¼k reach
    }

    def __init__(self, bearer_token: Optional[str] = None):
        """
        Args:
            bearer_token: X API Bearer Token
        """
        self.bearer_token = bearer_token or os.environ.get("X_BEARER_TOKEN")
        self.client = None

        if TWEEPY_AVAILABLE and self.bearer_token:
            self.client = tweepy.Client(bearer_token=self.bearer_token)

    def get_profile(self, username: str) -> Optional[XProfile]:
        """
        KullanÄ±cÄ± profilini Ã§eker.

        Args:
            username: X kullanÄ±cÄ± adÄ± (@olmadan)

        Returns:
            XProfile objesi veya None
        """
        if not self.client:
            return None

        try:
            user = self.client.get_user(
                username=username,
                user_fields=[
                    "created_at", "description", "public_metrics",
                    "profile_image_url", "verified"
                ]
            )

            if user.data:
                return XProfile(
                    username=user.data.username,
                    name=user.data.name,
                    followers_count=user.data.public_metrics["followers_count"],
                    following_count=user.data.public_metrics["following_count"],
                    tweet_count=user.data.public_metrics["tweet_count"],
                    created_at=str(user.data.created_at),
                    verified=getattr(user.data, 'verified', False),
                    description=user.data.description or "",
                    profile_image_url=user.data.profile_image_url or ""
                )
        except Exception as e:
            print(f"Profil Ã§ekme hatasÄ±: {e}")

        return None

    def analyze_profile(self, profile: XProfile) -> Dict:
        """
        Profili analiz eder ve engagement faktÃ¶rleri hesaplar.

        Args:
            profile: XProfile objesi

        Returns:
            Analiz sonuÃ§larÄ±
        """
        analysis = {
            "tier": profile.engagement_tier,
            "tier_multiplier": self.TIER_MULTIPLIERS[profile.engagement_tier],
            "strengths": [],
            "weaknesses": [],
            "suggestions": [],
            "metrics": {}
        }

        # TakipÃ§i sayÄ±sÄ± analizi
        if profile.followers_count >= 10000:
            analysis["strengths"].append(f"GÃ¼Ã§lÃ¼ takipÃ§i tabanÄ±: {profile.followers_count:,}")
        elif profile.followers_count < 100:
            analysis["weaknesses"].append("DÃ¼ÅŸÃ¼k takipÃ§i sayÄ±sÄ± - reach sÄ±nÄ±rlÄ±")
            analysis["suggestions"].append("TutarlÄ± iÃ§erik ve etkileÅŸim ile takipÃ§i artÄ±rÄ±n")

        # TakipÃ§i/Takip oranÄ±
        ratio = profile.follower_ratio
        if ratio >= 2:
            analysis["strengths"].append(f"YÃ¼ksek takipÃ§i oranÄ±: {ratio:.1f}x")
        elif ratio < 0.5:
            analysis["weaknesses"].append("DÃ¼ÅŸÃ¼k takipÃ§i oranÄ± - otorite sorgulanabilir")

        # Hesap yaÅŸÄ±
        age_days = profile.account_age_days
        if age_days >= 365:
            years = age_days // 365
            analysis["strengths"].append(f"YerleÅŸik hesap: {years}+ yÄ±l")
        elif age_days < 90:
            analysis["weaknesses"].append("Yeni hesap - gÃ¼ven inÅŸasÄ± gerekli")
            analysis["suggestions"].append("DÃ¼zenli paylaÅŸÄ±m yaparak gÃ¼ven oluÅŸturun")

        # Tweet sayÄ±sÄ±
        if profile.tweet_count >= 1000:
            analysis["strengths"].append("Aktif iÃ§erik Ã¼retici")
        elif profile.tweet_count < 50:
            analysis["suggestions"].append("Daha fazla iÃ§erik Ã¼retin")

        # Verified badge
        if profile.verified:
            analysis["strengths"].append("DoÄŸrulanmÄ±ÅŸ hesap [OK]")
            analysis["tier_multiplier"] *= 1.2

        # Metrikleri kaydet
        analysis["metrics"] = {
            "followers": profile.followers_count,
            "following": profile.following_count,
            "tweets": profile.tweet_count,
            "ratio": round(ratio, 2),
            "age_days": age_days,
            "verified": profile.verified
        }

        return analysis

    def calculate_reach_prediction(
        self,
        profile: XProfile,
        tweet_score: float,
        posting_hour: Optional[int] = None,
        posting_day: Optional[int] = None,
        content_type: str = "text_only",
        has_trending_hashtag: bool = False,
        tweetcred_score: Optional[int] = None
    ) -> Dict[str, any]:
        """
        GerÃ§ekÃ§i reach tahmini hesaplar.

        FaktÃ¶rler:
        - TakipÃ§i sayÄ±sÄ± ve tier
        - Tweet kalite skoru
        - Posting zamanÄ± (saat ve gÃ¼n)
        - Ä°Ã§erik tipi (media, thread, vb.)
        - TweetCred skoru (hesap otoritesi)
        - Viral potansiyel

        Args:
            profile: XProfile objesi
            tweet_score: Tweet analiz skoru (0-100)
            posting_hour: Tweet atÄ±lacak saat (0-23, None = ÅŸu anki saat)
            posting_day: Tweet atÄ±lacak gÃ¼n (0=Pazartesi, 6=Pazar, None = bugÃ¼n)
            content_type: Ä°Ã§erik tipi (text_only, with_image, with_video, vb.)
            has_trending_hashtag: Trend hashtag kullanÄ±lÄ±yor mu
            tweetcred_score: TweetCred skoru (None = tahmin et)

        Returns:
            DetaylÄ± reach tahmini
        """
        from datetime import datetime

        # VarsayÄ±lan deÄŸerler
        now = datetime.now()
        if posting_hour is None:
            posting_hour = now.hour
        if posting_day is None:
            posting_day = now.weekday()

        # ============ BASE REACH HESAPLAMA ============
        base_followers = profile.followers_count

        # X algoritmasÄ±: Organik reach = takipÃ§ilerin %5-15'i (tier'a baÄŸlÄ±)
        organic_reach_rate = {
            "mega": 0.03,     # 1M+ hesaplar sadece %3
            "macro": 0.05,    # 100K+ %5
            "mid": 0.08,      # 10K+ %8
            "micro": 0.12,    # 1K+ %12
            "nano": 0.15,     # 100+ %15
            "starter": 0.20   # <100 %20 (ama dÃ¼ÅŸÃ¼k sayÄ±lar)
        }

        base_organic_rate = organic_reach_rate.get(profile.engagement_tier, 0.10)
        base_reach = int(base_followers * base_organic_rate)

        # ============ MULTIPLIER'LAR ============

        # 1. Tweet kalite skoru (0-100 -> 0.5-1.5 multiplier)
        quality_mult = 0.5 + (tweet_score / 100)

        # 2. Saat multiplier'Ä±
        hour_mult = HOURLY_ENGAGEMENT_MULTIPLIERS.get(posting_hour, 1.0)

        # 3. GÃ¼n multiplier'Ä±
        day_mult = DAILY_ENGAGEMENT_MULTIPLIERS.get(posting_day, 1.0)

        # 4. Ä°Ã§erik tipi multiplier'Ä±
        content_mult = CONTENT_TYPE_MULTIPLIERS.get(content_type, 1.0)

        # 5. TweetCred multiplier (hesap otoritesi)
        if tweetcred_score is None:
            # Basit tahmin: verified +50, takipÃ§i oranÄ±na gÃ¶re +/-
            estimated_cred = -128 + (100 if profile.verified else 0)
            if profile.follower_ratio > 2:
                estimated_cred += 30
            if profile.tweet_count > 1000:
                estimated_cred += 20
            tweetcred_score = estimated_cred

        # TweetCred -> multiplier dÃ¶nÃ¼ÅŸÃ¼mÃ¼
        if tweetcred_score >= 50:
            cred_mult = 1.5
        elif tweetcred_score >= 17:
            cred_mult = 1.0
        elif tweetcred_score >= -50:
            cred_mult = 0.5
        else:
            cred_mult = 0.1  # Cold start suppression

        # 6. Viral potansiyel
        viral_mult = 1.0
        if has_trending_hashtag:
            viral_mult *= VIRAL_FACTORS.get("trending_hashtag", 2.0)

        # ============ TOPLAM REACH HESAPLAMA ============

        # TÃ¼m multiplier'larÄ± birleÅŸtir
        total_mult = quality_mult * hour_mult * day_mult * content_mult * cred_mult * viral_mult

        # Algoritmik boost potansiyeli (For You'da gÃ¶rÃ¼nme)
        # YÃ¼ksek engagement ilk 30 dakikada -> boost
        foryou_boost = 1.0
        if total_mult > 1.5:
            foryou_boost = 1.5  # For You'da gÃ¶rÃ¼nme ÅŸansÄ±
        elif total_mult > 1.2:
            foryou_boost = 1.2

        # Final impressions
        impressions = int(base_reach * total_mult * foryou_boost)

        # Minimum 10, maksimum takipÃ§i * 10 (viral limit)
        impressions = max(10, min(impressions, base_followers * 10))

        # ============ ENGAGEMENT TAHMÄ°NÄ° ============

        # Base engagement rate (tier'a gÃ¶re)
        tier_engagement_rate = {
            "mega": 0.01,     # %1
            "macro": 0.02,    # %2
            "mid": 0.03,      # %3
            "micro": 0.05,    # %5
            "nano": 0.08,     # %8
            "starter": 0.10   # %10
        }

        base_eng_rate = tier_engagement_rate.get(profile.engagement_tier, 0.03)

        # Kalite ve zamanlamaya gÃ¶re engagement artÄ±ÅŸÄ±
        adjusted_eng_rate = base_eng_rate * (quality_mult * 0.7 + 0.3)

        engagements = int(impressions * adjusted_eng_rate)

        # Engagement daÄŸÄ±lÄ±mÄ± (X algorithm analytics'e dayalÄ±)
        likes = int(engagements * 0.55)           # %55 like
        retweets = int(engagements * 0.08)        # %8 retweet
        replies = int(engagements * 0.12)         # %12 reply
        bookmarks = int(engagements * 0.15)       # %15 bookmark
        quotes = int(engagements * 0.03)          # %3 quote
        profile_visits = int(engagements * 0.07)  # %7 profil ziyareti

        # ============ ZAMANLAMA ANALÄ°ZÄ° ============

        # Optimal saat kontrolÃ¼
        optimal_score = int(hour_mult * day_mult * 50)  # 0-100 arasÄ±

        if hour_mult >= 1.3:
            timing_quality = "Mukemmel"
        elif hour_mult >= 1.0:
            timing_quality = "Iyi"
        elif hour_mult >= 0.7:
            timing_quality = "Orta"
        else:
            timing_quality = "Zayif"

        # En iyi alternatif saatler
        best_hours = sorted(
            HOURLY_ENGAGEMENT_MULTIPLIERS.items(),
            key=lambda x: x[1],
            reverse=True
        )[:3]

        return {
            # Temel metrikler
            "impressions": impressions,
            "engagements": engagements,
            "likes": likes,
            "retweets": retweets,
            "replies": replies,
            "bookmarks": bookmarks,
            "quotes": quotes,
            "profile_visits": profile_visits,
            "engagement_rate": round((engagements / max(impressions, 1)) * 100, 2),

            # Multiplier detaylarÄ±
            "multipliers": {
                "quality": round(quality_mult, 2),
                "hour": round(hour_mult, 2),
                "day": round(day_mult, 2),
                "content": round(content_mult, 2),
                "tweetcred": round(cred_mult, 2),
                "viral": round(viral_mult, 2),
                "foryou_boost": round(foryou_boost, 2),
                "total": round(total_mult * foryou_boost, 2)
            },

            # Zamanlama analizi
            "timing": {
                "posting_hour": posting_hour,
                "posting_day": posting_day,
                "quality": timing_quality,
                "score": optimal_score,
                "best_hours": [{"hour": h, "multiplier": m} for h, m in best_hours]
            },

            # Reach aralÄ±ÄŸÄ± (min-max tahmini)
            "reach_range": {
                "pessimistic": int(impressions * 0.5),
                "expected": impressions,
                "optimistic": int(impressions * 2.0),
                "viral_potential": int(impressions * 5.0) if viral_mult > 1 else None
            },

            # Hesap bilgisi
            "account": {
                "tier": profile.engagement_tier,
                "tweetcred_estimate": tweetcred_score,
                "organic_reach_rate": f"{base_organic_rate*100:.1f}%"
            }
        }

    def get_optimal_posting_times(self, timezone: str = "TR") -> Dict[str, any]:
        """
        Optimal tweet atma zamanlarini dondurur.

        Args:
            timezone: Saat dilimi (TR = Turkiye UTC+3)

        Returns:
            Optimal zamanlar ve onerileri
        """
        from datetime import datetime

        now = datetime.now()
        current_hour = now.hour
        current_day = now.weekday()

        # En iyi saatler
        sorted_hours = sorted(
            HOURLY_ENGAGEMENT_MULTIPLIERS.items(),
            key=lambda x: x[1],
            reverse=True
        )

        top_hours = sorted_hours[:5]  # En iyi 5 saat
        worst_hours = sorted_hours[-5:]  # En kotu 5 saat

        # En iyi gunler
        sorted_days = sorted(
            DAILY_ENGAGEMENT_MULTIPLIERS.items(),
            key=lambda x: x[1],
            reverse=True
        )

        day_names = ["Pazartesi", "Sali", "Carsamba", "Persembe", "Cuma", "Cumartesi", "Pazar"]

        # Simdi icin skor
        current_score = (
            HOURLY_ENGAGEMENT_MULTIPLIERS.get(current_hour, 1.0) *
            DAILY_ENGAGEMENT_MULTIPLIERS.get(current_day, 1.0)
        )

        # Bugunun kalan saatleri icin en iyi zaman
        best_remaining_hour = None
        best_remaining_mult = 0
        for hour in range(current_hour + 1, 24):
            mult = HOURLY_ENGAGEMENT_MULTIPLIERS.get(hour, 1.0)
            if mult > best_remaining_mult:
                best_remaining_mult = mult
                best_remaining_hour = hour

        # Oneri olustur
        if current_score >= 1.3:
            recommendation = "Simdi mukemmel bir zaman! Hemen tweetle."
        elif current_score >= 1.0:
            recommendation = "Simdi iyi bir zaman. Tweetleyebilirsin."
        elif best_remaining_hour:
            recommendation = f"Bekle! Bugun saat {best_remaining_hour:02d}:00'da daha iyi (x{best_remaining_mult:.1f})."
        else:
            recommendation = "Yarin sabah 09:00-12:00 arasi daha iyi olur."

        return {
            "current": {
                "hour": current_hour,
                "day": day_names[current_day],
                "score": round(current_score * 50, 0),  # 0-100 arasi
                "multiplier": round(current_score, 2)
            },
            "recommendation": recommendation,
            "best_hours": [
                {
                    "hour": h,
                    "time": f"{h:02d}:00",
                    "multiplier": round(m, 2),
                    "label": "Prime Time" if m >= 1.3 else "Iyi" if m >= 1.0 else "Normal"
                }
                for h, m in top_hours
            ],
            "worst_hours": [
                {
                    "hour": h,
                    "time": f"{h:02d}:00",
                    "multiplier": round(m, 2)
                }
                for h, m in worst_hours
            ],
            "best_days": [
                {
                    "day": d,
                    "name": day_names[d],
                    "multiplier": round(m, 2)
                }
                for d, m in sorted_days[:3]
            ],
            "optimal_slots": OPTIMAL_POSTING_HOURS_TR,
            "today_remaining_best": {
                "hour": best_remaining_hour,
                "time": f"{best_remaining_hour:02d}:00" if best_remaining_hour else None,
                "multiplier": round(best_remaining_mult, 2) if best_remaining_hour else None
            } if best_remaining_hour else None
        }

    def create_manual_profile(
        self,
        username: str,
        followers: int,
        following: int = 0,
        tweets: int = 0,
        verified: bool = False,
        account_age_years: float = 1
    ) -> XProfile:
        """
        API olmadan manuel profil oluÅŸturur.

        Args:
            username: KullanÄ±cÄ± adÄ±
            followers: TakipÃ§i sayÄ±sÄ±
            following: Takip sayÄ±sÄ±
            tweets: Tweet sayÄ±sÄ±
            verified: DoÄŸrulanmÄ±ÅŸ mÄ±
            account_age_years: Hesap yaÅŸÄ± (yÄ±l)

        Returns:
            XProfile objesi
        """
        from datetime import datetime, timedelta

        created_date = datetime.now() - timedelta(days=int(account_age_years * 365))

        return XProfile(
            username=username,
            name=username,
            followers_count=followers,
            following_count=following,
            tweet_count=tweets,
            created_at=created_date.strftime("%Y-%m-%dT%H:%M:%S.000Z"),
            verified=verified,
            description=""
        )


@dataclass
class TweetTemplate:
    """Tweet ÅŸablonu"""
    name: str
    template: str
    description: str
    engagement_boost: float
    category: str = "general"


class XAlgorithmTweetGenerator:
    """
    X AlgoritmasÄ± tabanlÄ± Tweet Generator

    For You feed'inde gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼ artÄ±rmak iÃ§in
    algoritmanÄ±n favori ettiÄŸi Ã¶zellikleri kullanÄ±r.
    """

    # ============================================================================
    # X ALGORÄ°TMASI ENGAGEMENT FAKTÃ–RLER (Phoenix WeightedScorer analizi)
    # ============================================================================

    # Engagement artÄ±ran faktÃ¶rler (X algoritmasÄ± aÄŸÄ±rlÄ±klarÄ±na gÃ¶re)
    ENGAGEMENT_BOOSTERS = {
        # Reply tetikleyiciler (en deÄŸerli - 1.0 aÄŸÄ±rlÄ±k)
        "question": 1.35,               # Soru = Reply olasÄ±lÄ±ÄŸÄ± yÃ¼ksek
        "call_to_action": 1.30,         # CTA = Share + Reply tetikler
        "controversy": 1.40,            # TartÄ±ÅŸmalÄ± = YÃ¼ksek engagement

        # Storytelling & Thread (Quote ve RT tetikler - 1.0 aÄŸÄ±rlÄ±k)
        "storytelling": 1.25,           # Hikaye = Dwell time artÄ±rÄ±r
        "thread_hook": 1.45,            # Thread = Follow tetikler (4.0 aÄŸÄ±rlÄ±k!)

        # Visual content (Photo expand - 0.5 aÄŸÄ±rlÄ±k)
        "visual_content": 1.20,         # GÃ¶rsel = Dwell + Expand

        # Profile click tetikleyiciler (1.0 aÄŸÄ±rlÄ±k)
        "personal_experience": 1.25,    # KiÅŸisel hikaye = Profile click
        "authority_signal": 1.30,       # Otorite gÃ¶sterimi = Follow

        # Timely content
        "timely_topic": 1.25,           # GÃ¼ncel konu = KeÅŸfet gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼

        # Data & Insight
        "data_insight": 1.20,           # Veri = Bookmark (share_via_copy)

        # Formatting
        "emoji_moderate": 1.10,         # 1-5 emoji = Dikkat Ã§ekici
        "line_breaks": 1.15,            # Format = Dwell time
        "long_form_value": 1.25,        # Uzun iÃ§erik = DeÄŸerli

        # Share tetikleyiciler (1.0-1.5 aÄŸÄ±rlÄ±k)
        "shareable_insight": 1.35,      # PaylaÅŸÄ±labilir iÃ§gÃ¶rÃ¼
        "quotable_line": 1.30,          # AlÄ±ntÄ±lanabilir cÃ¼mle
    }

    # Engagement dÃ¼ÅŸÃ¼ren faktÃ¶rler (Negatif sinyaller - X algoritmasÄ±)
    ENGAGEMENT_PENALTIES = {
        # Kritik cezalar (algoritma direkt bastÄ±rÄ±r)
        "external_link": 0.50,          # DÄ±ÅŸ link = %50 dÃ¼ÅŸÃ¼ÅŸ (ciddi ceza)
        "spam_keywords": 0.30,          # Spam = %70 dÃ¼ÅŸÃ¼ÅŸ

        # Orta cezalar
        "too_many_hashtags": 0.70,      # 3+ hashtag = Spam gÃ¶rÃ¼nÃ¼mÃ¼
        "all_caps": 0.75,               # BÃ¼yÃ¼k harf = Agresif
        "emoji_overload": 0.80,         # 10+ emoji = Spam
        "no_engagement_hook": 0.85,     # Hook yok = DÃ¼ÅŸÃ¼k etkileÅŸim

        # Hafif cezalar
        "repetitive_content": 0.90,     # Tekrar = DÃ¼ÅŸÃ¼k deÄŸer
        "low_effort": 0.85,             # Az emek = DÃ¼ÅŸÃ¼k kalite

        # Negatif sinyal tetikleyiciler (block/mute/report riski)
        "aggressive_tone": 0.70,        # SaldÄ±rgan ton = Block riski
        "misleading_content": 0.60,     # YanÄ±ltÄ±cÄ± = Report riski
    }

    # Phoenix Multi-Action Prediction AÄŸÄ±rlÄ±klarÄ±
    # (X'in gerÃ§ek weighted scorer'Ä±ndan)
    PHOENIX_WEIGHTS = {
        "favorite": 0.5,
        "reply": 1.0,
        "retweet": 1.0,
        "quote": 1.0,
        "click": 0.5,
        "profile_click": 1.0,
        "photo_expand": 0.5,
        "video_quality_view": 0.3,
        "share": 1.0,
        "share_via_dm": 1.5,
        "share_via_copy_link": 1.0,
        "dwell": 0.25,
        "dwell_time_continuous": 0.1,
        "follow_author": 4.0,  # En yÃ¼ksek!
        # Negatif
        "not_interested": -1.0,
        "block_author": -1.0,
        "mute_author": -1.0,
        "report": -1.0,
    }

    # GeniÅŸletilmiÅŸ viral tweet ÅŸablonlarÄ±
    TEMPLATES: List[TweetTemplate] = [
        # Thread & Hook ÅŸablonlarÄ±
        TweetTemplate(
            name="thread_epic",
            template="""ðŸ§µ {konu} hakkÄ±nda kimsenin anlatmadÄ±ÄŸÄ± gerÃ§ekler:

YÄ±llardÄ±r bu alanda Ã§alÄ±ÅŸÄ±yorum ve gÃ¶rdÃ¼klerim sizi ÅŸaÅŸÄ±rtacak.

HazÄ±rsanÄ±z baÅŸlÄ±yoruz ðŸ‘‡""",
            description="Epik thread aÃ§Ä±lÄ±ÅŸÄ±",
            engagement_boost=1.45,
            category="thread"
        ),
        TweetTemplate(
            name="contrarian_take",
            template="""Herkes {yaygin_inanc} diyor.

Ben tam tersini dÃ¼ÅŸÃ¼nÃ¼yorum.

Ä°ÅŸte nedeni:

{neden}

Unpopular opinion ama arkasÄ±ndayÄ±m.""",
            description="KarÅŸÄ±t gÃ¶rÃ¼ÅŸ - tartÄ±ÅŸma baÅŸlatÄ±cÄ±",
            engagement_boost=1.5,
            category="opinion"
        ),
        TweetTemplate(
            name="failure_story",
            template="""En bÃ¼yÃ¼k baÅŸarÄ±sÄ±zlÄ±ÄŸÄ±m:

{basarisizlik}

O gÃ¼n Ã¶ÄŸrendiÄŸim ÅŸey hayatÄ±mÄ± deÄŸiÅŸtirdi:

{ogrenilen}

BaÅŸarÄ±sÄ±zlÄ±k en iyi Ã¶ÄŸretmen.""",
            description="BaÅŸarÄ±sÄ±zlÄ±k hikayesi - Ã¶zgÃ¼n ve gÃ¼Ã§lÃ¼",
            engagement_boost=1.4,
            category="story"
        ),
        TweetTemplate(
            name="hot_prediction",
            template="""Tahminim:

{tahmin}

6 ay iÃ§inde herkes bundan bahsedecek.

Screenshot alÄ±n. ðŸ“¸""",
            description="Cesur tahmin",
            engagement_boost=1.35,
            category="prediction"
        ),
        TweetTemplate(
            name="myth_destruction",
            template=""""{mit}"

Bu cÃ¼mleyi duymaktan bÄ±ktÄ±m.

GerÃ§ek ÅŸu:

{gercek}

KanÄ±t mÄ±? {kanit}""",
            description="Mit yÄ±kÄ±cÄ± - agresif",
            engagement_boost=1.4,
            category="education"
        ),
        TweetTemplate(
            name="raw_honesty",
            template="""Bunu sÃ¶ylemek zor ama:

{itiraf}

Uzun sÃ¼re bununla yaÅŸadÄ±m.

ArtÄ±k deÄŸil.

{cozum}""",
            description="Ham dÃ¼rÃ¼stlÃ¼k - duygusal baÄŸ",
            engagement_boost=1.35,
            category="personal"
        ),
        TweetTemplate(
            name="framework_reveal",
            template="""10 yÄ±lda Ã¶ÄŸrendiÄŸim {konu} framework'Ã¼:

1ï¸âƒ£ {adim1}
2ï¸âƒ£ {adim2}
3ï¸âƒ£ {adim3}
4ï¸âƒ£ {adim4}
5ï¸âƒ£ {adim5}

Bu sistemi uygulayan herkes sonuÃ§ alÄ±yor.

Kaydet. Uygula. SonuÃ§ al.""",
            description="Framework/sistem paylaÅŸÄ±mÄ±",
            engagement_boost=1.3,
            category="education"
        ),
        TweetTemplate(
            name="behind_scenes",
            template="""Kimsenin gÃ¶rmediÄŸi taraf:

{gorunmeyen}

Herkes sonucu gÃ¶rÃ¼yor.
Kimse sÃ¼reci sormuyor.

Ä°ÅŸte gerÃ§ek:

{gercek}""",
            description="Perde arkasÄ± - ÅŸeffaflÄ±k",
            engagement_boost=1.35,
            category="personal"
        ),
        TweetTemplate(
            name="question_bomb",
            template="""{soru}

CevabÄ± bildiÄŸinizi sanÄ±yorsunuz ama...

GerÃ§ek cevap sizi ÅŸaÅŸÄ±rtacak.

(Yorumlarda tahminlerinizi bekliyorum)""",
            description="Soru bombasÄ± - merak uyandÄ±rÄ±cÄ±",
            engagement_boost=1.4,
            category="engagement"
        ),
        TweetTemplate(
            name="comparison_shock",
            template="""{eski_yontem} â†’ GeÃ§miÅŸte kaldÄ±

{yeni_yontem} â†’ Yeni standart

HÃ¢lÃ¢ eski yÃ¶ntemle devam edenler:

Bu deÄŸiÅŸimi kaÃ§Ä±rmayÄ±n.

Ä°ÅŸte neden: {neden}""",
            description="KarÅŸÄ±laÅŸtÄ±rma ÅŸoku",
            engagement_boost=1.3,
            category="education"
        ),
        TweetTemplate(
            name="long_form_story",
            template="""Bir hikaye anlatacaÄŸÄ±m.

{yil} yÄ±lÄ±nda, {durum} iÃ§indeydim.

{olay1}

Sonra beklenmedik bir ÅŸey oldu:

{olay2}

Bu an her ÅŸeyi deÄŸiÅŸtirdi.

{sonuc}

Ã–ÄŸrendiÄŸim en Ã¶nemli ÅŸey:

{ders}

Bu hikayeyi paylaÅŸmamÄ±n nedeni:

{neden}

EÄŸer sen de benzer bir durumda hissediyorsan, bil ki:

{mesaj}

---

Bu post'u kaydet.
Ä°htiyacÄ±n olduÄŸunda tekrar oku.

Ve eÄŸer tanÄ±dÄ±ÄŸÄ±n biri varsa bu durumda, paylaÅŸ.

Birlikte daha gÃ¼Ã§lÃ¼yÃ¼z. ðŸ’ª""",
            description="Uzun form hikaye - X Premium iÃ§in",
            engagement_boost=1.5,
            category="long_form"
        ),
        TweetTemplate(
            name="expertise_dump",
            template="""Son {sure} yÄ±lda {alan} alanÄ±nda Ã¶ÄŸrendiÄŸim her ÅŸey:

ðŸ“Œ TEMEL PRENSÄ°PLER:
â€¢ {prensip1}
â€¢ {prensip2}
â€¢ {prensip3}

ðŸ”§ PRATÄ°K TAKTÄ°KLER:
â€¢ {taktik1}
â€¢ {taktik2}
â€¢ {taktik3}

âš ï¸ YAPILMAMASI GEREKENLER:
â€¢ {hata1}
â€¢ {hata2}
â€¢ {hata3}

ðŸŽ¯ SONUÃ‡:
{sonuc}

Bu post'u bookmark'la.
{alan} ile ilgili tek rehber bu olsun.

SorularÄ±nÄ±z varsa yorumlarda buluÅŸalÄ±m. ðŸ‘‡""",
            description="UzmanlÄ±k dÃ¶kÃ¼mÃ¼ - deÄŸer dolu",
            engagement_boost=1.45,
            category="long_form"
        ),
        TweetTemplate(
            name="reality_check",
            template="""GerÃ§eklik kontrolÃ¼:

âŒ {yanlis1}
âŒ {yanlis2}
âŒ {yanlis3}

âœ… GerÃ§ek:

{gercek}

Kabul etmesi zor ama gerekli.""",
            description="GerÃ§eklik kontrolÃ¼",
            engagement_boost=1.35,
            category="opinion"
        ),
        TweetTemplate(
            name="vulnerable_share",
            template="""BugÃ¼n zor bir ÅŸey paylaÅŸacaÄŸÄ±m.

{paylasim}

Bunu neden anlatÄ±yorum?

Ã‡Ã¼nkÃ¼ {neden}

EÄŸer sen de bÃ¶yle hissediyorsan:

{mesaj}

DM'lerim aÃ§Ä±k. YalnÄ±z deÄŸilsin.""",
            description="KÄ±rÄ±lgan paylaÅŸÄ±m - derin baÄŸ",
            engagement_boost=1.4,
            category="personal"
        ),
        TweetTemplate(
            name="simple_truth",
            template="""{basit_gercek}

Hepsi bu.

KarmaÅŸÄ±klaÅŸtÄ±rmayÄ± bÄ±rakÄ±n.""",
            description="Basit gerÃ§ek - minimal ama gÃ¼Ã§lÃ¼",
            engagement_boost=1.25,
            category="opinion"
        ),
    ]

    # Spam kelimeleri (engagement dÃ¼ÅŸÃ¼rÃ¼r)
    SPAM_KEYWORDS = [
        "follow for follow", "f4f", "like4like", "dm for collab",
        "buy now", "limited offer", "click link", "free money",
        "giveaway follow", "retweet to win"
    ]

    def __init__(
        self,
        api_key: Optional[str] = None,
        is_premium: bool = True,
        x_bearer_token: Optional[str] = None
    ):
        """
        Args:
            api_key: Anthropic API key (opsiyonel, env'den de alÄ±nabilir)
            is_premium: X Premium kullanÄ±cÄ±sÄ± mÄ± (25k karakter)
            x_bearer_token: X API Bearer Token (profil analizi iÃ§in)
        """
        self.templates = self.TEMPLATES
        self.is_premium = is_premium
        self.max_chars = MAX_CHARS_PREMIUM if is_premium else MAX_CHARS_STANDARD

        # Claude API kurulumu
        self.api_key = api_key or os.environ.get("ANTHROPIC_API_KEY")
        self.client = None
        if ANTHROPIC_AVAILABLE and self.api_key:
            self.client = anthropic.Anthropic(api_key=self.api_key)

        # X Profile Analyzer kurulumu
        self.profile_analyzer = XProfileAnalyzer(bearer_token=x_bearer_token)
        self.current_profile: Optional[XProfile] = None

    def calculate_phoenix_score(self, action_predictions: Dict[str, float]) -> Dict[str, any]:
        """
        Phoenix Weighted Scorer - X algoritmasÄ±nÄ±n gerÃ§ek puanlama sistemi.

        X'in Rust codebase'inden alÄ±nan aÄŸÄ±rlÄ±klarla weighted score hesaplar.

        Args:
            action_predictions: Her aksiyon iÃ§in tahmin edilen olasÄ±lÄ±klar
                {"favorite": 0.5, "reply": 0.3, "retweet": 0.2, ...}

        Returns:
            {
                "weighted_score": float,  # Toplam aÄŸÄ±rlÄ±klÄ± skor
                "action_contributions": dict,  # Her aksiyonun katkÄ±sÄ±
                "positive_sum": float,  # Pozitif sinyaller toplamÄ±
                "negative_sum": float,  # Negatif sinyaller toplamÄ±
                "normalized_score": float,  # 0-100 arasÄ± normalize skor
            }
        """
        weighted_sum = 0.0
        positive_sum = 0.0
        negative_sum = 0.0
        contributions = {}

        for action, weight in self.PHOENIX_WEIGHTS.items():
            prediction = action_predictions.get(action, 0.0)
            contribution = prediction * weight
            contributions[action] = contribution

            if weight > 0:
                positive_sum += contribution
            else:
                negative_sum += abs(contribution)

            weighted_sum += contribution

        # Negatif skor offset (X algoritmasÄ±ndan)
        if weighted_sum < 0:
            # Negatif skorlarÄ± normalize et
            total_negative_weights = sum(abs(w) for w in self.PHOENIX_WEIGHTS.values() if w < 0)
            weighted_sum = (weighted_sum + total_negative_weights) / total_negative_weights * NEGATIVE_SCORES_OFFSET
        else:
            weighted_sum += NEGATIVE_SCORES_OFFSET

        # 0-100 arasÄ± normalize et
        max_possible = sum(w for w in self.PHOENIX_WEIGHTS.values() if w > 0)
        normalized = min(100, max(0, (weighted_sum / max_possible) * 100))

        return {
            "weighted_score": round(weighted_sum, 4),
            "action_contributions": contributions,
            "positive_sum": round(positive_sum, 4),
            "negative_sum": round(negative_sum, 4),
            "normalized_score": round(normalized, 1),
        }

    def calculate_author_diversity_penalty(
        self,
        author_position: int,
        decay_factor: float = AUTHOR_DIVERSITY_DECAY,
        floor: float = AUTHOR_DIVERSITY_FLOOR
    ) -> float:
        """
        Author Diversity Scorer - AynÄ± yazarÄ±n tekrarlayan iÃ§eriÄŸini cezalandÄ±rÄ±r.

        X algoritmasÄ±, aynÄ± yazardan art arda gelen tweetleri cezalandÄ±rÄ±r.
        Ä°lk tweet: 1.0x, Ä°kinci: 0.5x, ÃœÃ§Ã¼ncÃ¼: 0.25x, ... minimum: 0.1x

        Args:
            author_position: YazarÄ±n kaÃ§Ä±ncÄ± tweet'i (0-indexed)
            decay_factor: Her tekrar iÃ§in decay oranÄ± (default: 0.5)
            floor: Minimum multiplier (default: 0.1)

        Returns:
            Diversity multiplier (0.1 - 1.0 arasÄ±)
        """
        # FormÃ¼l: (1.0 - floor) * decay^position + floor
        multiplier = (1.0 - floor) * (decay_factor ** author_position) + floor
        return round(multiplier, 3)

    def calculate_oon_adjustment(self, base_score: float, is_in_network: bool) -> float:
        """
        Out-of-Network Adjustment - Takip etmediÄŸin kiÅŸilerin iÃ§eriÄŸini ayarla.

        X algoritmasÄ±, takip etmediÄŸin kiÅŸilerin iÃ§eriklerine %20 penalty uygular.

        Args:
            base_score: Temel skor
            is_in_network: KullanÄ±cÄ± takip edilenler arasÄ±nda mÄ±

        Returns:
            AyarlanmÄ±ÅŸ skor
        """
        if not is_in_network:
            return base_score * OON_WEIGHT_FACTOR
        return base_score

    def analyze_tweet(self, tweet: str) -> TweetAnalysis:
        """
        Tweet'i X algoritmasÄ±na gÃ¶re analiz eder.
        """
        score = 100.0
        strengths = []
        weaknesses = []
        suggestions = []
        engagement_prediction = {}

        char_count = len(tweet)
        words = tweet.split()
        word_count = len(words)

        # TEMEL KALÄ°TE KONTROLLER (Ã¶nce bunlar)

        # 1. Ã‡ok kÄ±sa veya anlamsÄ±z iÃ§erik kontrolÃ¼
        if char_count < 10:
            weaknesses.append("Ã‡ok kÄ±sa - anlamlÄ± iÃ§erik yok")
            score = 5.0
            return TweetAnalysis(
                score=round(score, 1),
                strengths=strengths,
                weaknesses=weaknesses,
                suggestions=["En az 2-3 cÃ¼mlelik anlamlÄ± iÃ§erik yazÄ±n"],
                engagement_prediction={"favorite": 0.01, "reply": 0.01, "repost": 0.01, "bookmark": 0.01}
            )

        # 2. Kelime sayÄ±sÄ± kontrolÃ¼
        if word_count < 3:
            weaknesses.append("Ã‡ok az kelime - daha fazla baÄŸlam gerekli")
            score *= 0.3

        # 3. Gibberish/rastgele karakter tespiti
        # TÃ¼rkÃ§e ve Ä°ngilizce yaygÄ±n harfler
        valid_chars = set('abcÃ§defgÄŸhÄ±ijklmnoÃ¶pqrsÅŸtuÃ¼vwxyzABCÃ‡DEFGÄžHIÄ°JKLMNOÃ–PQRSÅžTUÃœVWXYZ0123456789 \n.,!?:;\'"-()[]{}@#$%&*+=/<>ðŸ§µðŸ‘‡ðŸ’¡âœ…âŒðŸ“ŠðŸŽ¯ðŸ’ªðŸ”¥âš¡ï¸ðŸ“ŒðŸ”¹ðŸ”¸â€¢')

        # Emoji'leri say ve Ã§Ä±kar
        emoji_pattern = re.compile(r'[\U0001F300-\U0001F9FF\U0001F600-\U0001F64F\U0001F680-\U0001F6FF\U00002702-\U000027B0]')
        text_without_emoji = emoji_pattern.sub('', tweet)

        # GeÃ§ersiz karakter oranÄ±
        invalid_char_count = sum(1 for c in text_without_emoji if c not in valid_chars)
        invalid_ratio = invalid_char_count / max(len(text_without_emoji), 1)

        if invalid_ratio > 0.3:
            weaknesses.append("Ã‡ok fazla anlamsÄ±z karakter tespit edildi")
            score *= 0.2

        # 4. Tekrarlayan karakter kontrolÃ¼ (aaaaaaa, !!!!!! gibi)
        repetition_pattern = re.findall(r'(.)\1{4,}', tweet)
        if repetition_pattern:
            weaknesses.append("AÅŸÄ±rÄ± karakter tekrarÄ± - spam gibi gÃ¶rÃ¼nÃ¼yor")
            score *= 0.5

        # 5. GerÃ§ek kelime ve iÃ§erik kalitesi kontrolÃ¼
        # YaygÄ±n TÃ¼rkÃ§e ve Ä°ngilizce kelimeler
        common_words = {
            # TÃ¼rkÃ§e
            'bir', 'bu', 've', 'iÃ§in', 'ile', 'de', 'da', 'ne', 'var', 'yok',
            'ben', 'sen', 'biz', 'siz', 'ama', 'Ã§ok', 'daha', 'en', 'gibi',
            'nasÄ±l', 'neden', 'nerede', 'kim', 'hangi', 'kaÃ§', 'ÅŸey', 'zaman',
            'Ã¶yle', 'bÃ¶yle', 'ÅŸu', 'her', 'hiÃ§', 'artÄ±k', 'hala', 'sadece',
            'ise', 'olan', 'olarak', 'sonra', 'Ã¶nce', 'Ã¼zere', 'kadar', 'gÃ¶re',
            'hakkÄ±nda', 'arasÄ±nda', 'dolayÄ±', 'raÄŸmen', 'karÅŸÄ±', 'doÄŸru',
            # Ä°ngilizce
            'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'being',
            'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',
            'should', 'may', 'might', 'must', 'can', 'to', 'of', 'in', 'for',
            'on', 'with', 'at', 'by', 'from', 'or', 'as', 'it', 'that', 'this',
            'but', 'not', 'you', 'all', 'we', 'they', 'her', 'his', 'my', 'your',
            'what', 'which', 'who', 'when', 'where', 'why', 'how', 'if', 'so',
            'just', 'like', 'think', 'know', 'want', 'need', 'see', 'way',
            'new', 'now', 'look', 'only', 'come', 'its', 'over', 'such', 'even',
            'very', 'after', 'most', 'also', 'made', 'well', 'back', 'through'
        }

        # Keyboard pattern tespiti (anlamsÄ±z yazÄ±m)
        keyboard_patterns = ['asdf', 'jkl', 'qwer', 'zxcv', 'uiop', 'ghjk',
                            'asd', 'fgh', 'jkl', 'qwe', 'rty', 'dfg', 'cvb', 'bnm']

        tweet_lower_clean = ''.join(c for c in tweet.lower() if c.isalpha())
        keyboard_spam = any(pattern in tweet_lower_clean for pattern in keyboard_patterns)

        if keyboard_spam:
            weaknesses.append("Klavye pattern'i tespit edildi - anlamsÄ±z iÃ§erik")
            score *= 0.15

        # GerÃ§ek kelime sayÄ±mÄ±
        recognized_words = 0
        for word in words:
            clean_word = ''.join(c for c in word.lower() if c.isalpha())
            if clean_word in common_words:
                recognized_words += 1

        # EÄŸer kelimeler var ama hiÃ§biri tanÄ±nmÄ±yorsa
        if word_count >= 3 and recognized_words == 0:
            # Ek kontrol: en az bir kelime 5+ karakter ve normal gÃ¶rÃ¼nÃ¼mlÃ¼ mÃ¼?
            long_normal_words = [w for w in words if len(w) >= 5 and
                                sum(1 for c in w.lower() if c in 'aeÄ±ioÃ¶uÃ¼') >= 1]
            if len(long_normal_words) == 0:
                weaknesses.append("AnlamlÄ± kelime bulunamadÄ±")
                score *= 0.25

        # 6. Sadece bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf veya sayÄ± kontrolÃ¼
        alpha_count = sum(1 for c in tweet if c.isalpha())
        if alpha_count < 5:
            weaknesses.append("Yeterli metin iÃ§eriÄŸi yok")
            score *= 0.3

        # EÄŸer temel kalite Ã§ok dÃ¼ÅŸÃ¼kse, erken dÃ¶n
        if score < 20:
            return TweetAnalysis(
                score=round(score, 1),
                strengths=strengths,
                weaknesses=weaknesses,
                suggestions=["AnlamlÄ±, okunabilir bir tweet yazÄ±n", "En az 2-3 cÃ¼mle kullanÄ±n"],
                engagement_prediction={"favorite": 0.02, "reply": 0.02, "repost": 0.01, "bookmark": 0.01}
            )

        # UZUNLUK DEÄžERLENDÄ°RMESÄ° (kalite kontrolÃ¼nden sonra)
        if self.is_premium:
            if char_count < 100:
                weaknesses.append("Tweet kÄ±sa - Premium'da daha fazla deÄŸer sunabilirsin")
                score *= 0.95
            elif 500 <= char_count <= 2000:
                strengths.append("Optimal uzun form iÃ§erik - detaylÄ± ve deÄŸerli")
                score *= self.ENGAGEMENT_BOOSTERS["long_form_value"]
            elif char_count > 5000:
                strengths.append("Epik iÃ§erik - tam bir makale deÄŸerinde")
                score *= 1.15
        else:
            if char_count < 50:
                weaknesses.append("Tweet Ã§ok kÄ±sa - daha fazla baÄŸlam ekleyin")
                score *= 0.9
            elif char_count > 250:
                suggestions.append("X Premium ile 25,000 karaktere kadar yazabilirsin")

        # Soru kontrolÃ¼
        if "?" in tweet:
            strengths.append("Soru iÃ§eriyor - reply olasÄ±lÄ±ÄŸÄ± yÃ¼ksek")
            score *= self.ENGAGEMENT_BOOSTERS["question"]
            engagement_prediction["reply"] = 0.7
        else:
            engagement_prediction["reply"] = 0.3

        # Emoji analizi
        emoji_count = len(re.findall(r'[\U0001F300-\U0001F9FF]', tweet))
        if 1 <= emoji_count <= 5:
            strengths.append("Ä°yi emoji kullanÄ±mÄ±")
            score *= self.ENGAGEMENT_BOOSTERS["emoji_moderate"]
        elif emoji_count > 10:
            weaknesses.append("Ã‡ok fazla emoji")
            score *= self.ENGAGEMENT_PENALTIES["emoji_overload"]

        # Hashtag analizi
        hashtag_count = len(re.findall(r'#\w+', tweet))
        if hashtag_count > 3:
            weaknesses.append("Ã‡ok fazla hashtag - spam gibi gÃ¶rÃ¼nÃ¼r")
            score *= self.ENGAGEMENT_PENALTIES["too_many_hashtags"]
        elif 1 <= hashtag_count <= 2:
            strengths.append("Ä°yi hashtag kullanÄ±mÄ±")

        # DÄ±ÅŸ link kontrolÃ¼
        if re.search(r'https?://(?!twitter\.com|x\.com)', tweet):
            weaknesses.append("DÄ±ÅŸ link - algoritma bunu cezalandÄ±rÄ±r")
            score *= self.ENGAGEMENT_PENALTIES["external_link"]
            suggestions.append("Linki yorumlara taÅŸÄ±mayÄ± dÃ¼ÅŸÃ¼nÃ¼n")

        # BÃ¼yÃ¼k harf kontrolÃ¼
        upper_ratio = sum(1 for c in tweet if c.isupper()) / max(len(tweet.replace(" ", "")), 1)
        if upper_ratio > 0.5:
            weaknesses.append("Ã‡ok fazla bÃ¼yÃ¼k harf")
            score *= self.ENGAGEMENT_PENALTIES["all_caps"]

        # Spam kelime kontrolÃ¼
        tweet_lower = tweet.lower()
        for spam_word in self.SPAM_KEYWORDS:
            if spam_word in tweet_lower:
                weaknesses.append(f"Spam kelimesi: '{spam_word}'")
                score *= self.ENGAGEMENT_PENALTIES["spam_keywords"]
                break

        # SatÄ±r arasÄ± (okunabilirlik)
        line_count = tweet.count("\n")
        if line_count >= 3:
            strengths.append("Ä°yi formatlanmÄ±ÅŸ - okunabilir")
            score *= self.ENGAGEMENT_BOOSTERS["line_breaks"]

        # Thread hook kontrolÃ¼
        if "ðŸ§µ" in tweet or "thread" in tweet_lower:
            strengths.append("Thread formatÄ± - yÃ¼ksek engagement")
            score *= self.ENGAGEMENT_BOOSTERS["thread_hook"]

        # Call to action kontrolÃ¼
        cta_patterns = ["yorumda", "belirtin", "paylaÅŸ", "ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz",
                       "katÄ±lÄ±yor musunuz", "hangisi", "kaydet", "bookmark",
                       "dm", "comment", "share", "ðŸ‘‡", "â¬‡ï¸"]
        has_cta = any(cta in tweet_lower for cta in cta_patterns)
        if has_cta:
            strengths.append("Call to action var - etkileÅŸim teÅŸviki")
            score *= self.ENGAGEMENT_BOOSTERS["call_to_action"]
        else:
            suggestions.append("Bir call to action ekle (Ã¶rn: 'Ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz? ðŸ‘‡')")

        # Skoru 0-100 arasÄ±nda sÄ±nÄ±rla
        score = max(0, min(100, score))

        # ============================================================================
        # PHOENIX-STYLE ENGAGEMENT PREDICTION (X AlgoritmasÄ± AÄŸÄ±rlÄ±klarÄ±)
        # ============================================================================

        # Base engagement olasÄ±lÄ±klarÄ± (skor bazlÄ±)
        base_engagement = score / 100

        # Her aksiyon iÃ§in Ã¶zel tahminler
        # Soru varsa reply yÃ¼ksek
        reply_boost = 1.5 if "?" in tweet else 1.0
        # CTA varsa share/bookmark yÃ¼ksek
        share_boost = 1.3 if has_cta else 1.0
        # Thread ise follow yÃ¼ksek
        follow_boost = 1.5 if ("ðŸ§µ" in tweet or "thread" in tweet_lower) else 1.0
        # GÃ¶rsel referansÄ± varsa photo_expand yÃ¼ksek
        visual_boost = 1.3 if any(w in tweet_lower for w in ["fotoÄŸraf", "gÃ¶rsel", "image", "pic", "ðŸ“·", "ðŸ–¼"]) else 1.0
        # Uzun iÃ§erik varsa dwell yÃ¼ksek
        dwell_boost = 1.4 if char_count > 200 else 1.0

        # Phoenix-style action predictions
        engagement_prediction = {
            # Pozitif aksiyonlar (aÄŸÄ±rlÄ±klara gÃ¶re sÄ±ralÄ±)
            "follow_author": min(base_engagement * 0.15 * follow_boost, 0.30),  # En deÄŸerli (4.0 aÄŸÄ±rlÄ±k)
            "share_via_dm": min(base_engagement * 0.20 * share_boost, 0.35),    # 1.5 aÄŸÄ±rlÄ±k
            "reply": min(base_engagement * 0.35 * reply_boost, 0.70),           # 1.0 aÄŸÄ±rlÄ±k
            "retweet": min(base_engagement * 0.30, 0.55),                       # 1.0 aÄŸÄ±rlÄ±k
            "quote": min(base_engagement * 0.25, 0.45),                         # 1.0 aÄŸÄ±rlÄ±k
            "share": min(base_engagement * 0.30 * share_boost, 0.50),           # 1.0 aÄŸÄ±rlÄ±k
            "profile_click": min(base_engagement * 0.40, 0.65),                 # 1.0 aÄŸÄ±rlÄ±k
            "favorite": min(base_engagement * 0.60, 0.85),                      # 0.5 aÄŸÄ±rlÄ±k (en yaygÄ±n)
            "click": min(base_engagement * 0.50, 0.75),                         # 0.5 aÄŸÄ±rlÄ±k
            "photo_expand": min(base_engagement * 0.35 * visual_boost, 0.55),   # 0.5 aÄŸÄ±rlÄ±k
            "bookmark": min(base_engagement * 0.25 * share_boost, 0.45),        # Tahmini
            "dwell": min(base_engagement * 0.70 * dwell_boost, 0.90),           # 0.25 aÄŸÄ±rlÄ±k

            # Negatif aksiyonlar (dÃ¼ÅŸÃ¼k olmalÄ±)
            "not_interested": max(0.02, (1 - base_engagement) * 0.15),
            "mute_author": max(0.01, (1 - base_engagement) * 0.08),
            "block_author": max(0.005, (1 - base_engagement) * 0.05),
            "report": max(0.001, (1 - base_engagement) * 0.02),
        }

        # Phoenix weighted score hesapla
        phoenix_result = self.calculate_phoenix_score(engagement_prediction)

        return TweetAnalysis(
            score=round(score, 1),
            strengths=strengths,
            weaknesses=weaknesses,
            suggestions=suggestions,
            engagement_prediction=engagement_prediction,
            profile_boost=phoenix_result["normalized_score"] / 100  # Phoenix score'u profile_boost olarak kullan
        )

    def generate_with_ai(
        self,
        topic: str,
        style: str = "professional",
        tone: str = "engaging",
        length: str = "medium",
        include_cta: bool = True,
        include_emoji: bool = True,
        custom_instructions: str = "",
        language: str = "tr",
        profile: XProfile = None
    ) -> str:
        """
        Claude AI ile yaratÄ±cÄ± tweet Ã¼retir.

        Args:
            topic: Tweet konusu
            style: Stil (professional, casual, provocative, storytelling, educational)
            tone: Ton (engaging, controversial, inspirational, humorous, raw)
            length: Uzunluk (short, medium, long, epic)
            include_cta: Call to action eklensin mi
            include_emoji: Emoji kullanÄ±lsÄ±n mÄ±
            custom_instructions: Ã–zel talimatlar
            language: Dil kodu (tr, en, de, fr, es, ar, zh, ja, ko, pt, ru)
            profile: X profil bilgisi (takipÃ§i, verified, hesap yaÅŸÄ±)

        Returns:
            Ãœretilen tweet
        """
        if not self.client:
            return "Claude API baÄŸlantÄ±sÄ± yok. ANTHROPIC_API_KEY ayarlayÄ±n."

        # Dil ayarlarÄ±
        language_config = {
            "tr": {"name": "TÃ¼rkÃ§e", "instruction": "Tweet'i TÃ¼rkÃ§e yaz."},
            "en": {"name": "English", "instruction": "Write the tweet in English."},
            "de": {"name": "Deutsch", "instruction": "Write the tweet in German (Deutsch)."},
            "fr": {"name": "FranÃ§ais", "instruction": "Write the tweet in French (FranÃ§ais)."},
            "es": {"name": "EspaÃ±ol", "instruction": "Write the tweet in Spanish (EspaÃ±ol)."},
            "ar": {"name": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "instruction": "Write the tweet in Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)."},
            "zh": {"name": "ä¸­æ–‡", "instruction": "Write the tweet in Chinese (ä¸­æ–‡)."},
            "ja": {"name": "æ—¥æœ¬èªž", "instruction": "Write the tweet in Japanese (æ—¥æœ¬èªž)."},
            "ko": {"name": "í•œêµ­ì–´", "instruction": "Write the tweet in Korean (í•œêµ­ì–´)."},
            "pt": {"name": "PortuguÃªs", "instruction": "Write the tweet in Portuguese (PortuguÃªs)."},
            "ru": {"name": "Ð ÑƒÑÑÐºÐ¸Ð¹", "instruction": "Write the tweet in Russian (Ð ÑƒÑÑÐºÐ¸Ð¹)."},
        }

        lang_info = language_config.get(language, language_config["tr"])
        lang_instruction = lang_info["instruction"]

        # Profil bazlÄ± strateji
        profile_strategy = ""
        if profile:
            followers = profile.followers_count
            is_verified = profile.verified

            if followers < 1000:
                profile_strategy = """
ðŸ‘¤ PROFÄ°L: BÃœYÃœME AÅžAMASI (< 1K takipÃ§i)
STRATEJÄ°:
- Viral potansiyeli YÃœKSEK iÃ§erik Ã¼ret (paylaÅŸÄ±labilir, relatable)
- Soru sor, tartÄ±ÅŸma baÅŸlat â†’ Reply ve RT al
- Trending konulara deÄŸin â†’ KeÅŸfet'e dÃ¼ÅŸ
- Niche topluluklara hitap et â†’ SadÄ±k takipÃ§i kazan
- Hook Ã§ok gÃ¼Ã§lÃ¼ olmalÄ± â†’ Scroll durdur
- KiÅŸisel hikaye ve deneyim paylaÅŸ â†’ BaÄŸ kur
- "Follow iÃ§in sebep ver" mantÄ±ÄŸÄ± â†’ DeÄŸer sun
"""
            elif followers < 10000:
                profile_strategy = """
ðŸ‘¤ PROFÄ°L: GELÄ°ÅžME AÅžAMASI (1K-10K takipÃ§i)
STRATEJÄ°:
- TutarlÄ± iÃ§erik Ã¼ret â†’ Marka oluÅŸtur
- Thread formatÄ± kullan â†’ Derin deÄŸer sun
- Engagement'Ä± koru â†’ Mevcut kitleyi kaybetme
- Niche'te otorite ol â†’ Spesifik konularda derinleÅŸ
- DiÄŸer hesaplarla etkileÅŸim â†’ Networking
- Quote tweet ile gÃ¶rÃ¼ÅŸ bildir â†’ GÃ¶rÃ¼nÃ¼rlÃ¼k
"""
            elif followers < 100000:
                profile_strategy = """
ðŸ‘¤ PROFÄ°L: MÄ°D-TÄ°ER (10K-100K takipÃ§i)
STRATEJÄ°:
- Otoriter ve gÃ¼venilir ton kullan
- DeÄŸer odaklÄ± iÃ§erik â†’ Kaliteyi koru
- Kendi gÃ¶rÃ¼ÅŸlerini cesurca paylaÅŸ
- Trend belirleyici ol, takip etme
- Thread ve uzun iÃ§erik â†’ Dwell time
- TartÄ±ÅŸmalÄ± konularda pozisyon al
"""
            else:
                profile_strategy = """
ðŸ‘¤ PROFÄ°L: BÃœYÃœK HESAP (100K+ takipÃ§i)
STRATEJÄ°:
- Otorite ve liderlik tonu
- Orijinal dÃ¼ÅŸÃ¼nce ve iÃ§gÃ¶rÃ¼ sun
- KÄ±sa, vurucu mesajlar da iÅŸe yarar (zaten gÃ¶rÃ¼nÃ¼rlÃ¼ÄŸÃ¼n var)
- Topluluk oluÅŸtur, kitleyi yÃ¶nlendir
- Marka deÄŸerini koru, tartÄ±ÅŸmalÄ± konularda dikkatli ol
- DiÄŸer bÃ¼yÃ¼k hesaplarla etkileÅŸim
"""

            if is_verified:
                profile_strategy += """
[OK] VERÄ°FÄ°ED AVANTAJI:
- TweetCred +100 boost â†’ Daha geniÅŸ daÄŸÄ±tÄ±m
- Duplicate content'te %30 muafiyet
- Daha cesur ve tartÄ±ÅŸmalÄ± olabilirsin
- Otorite sinyali gÃ¼Ã§lÃ¼
"""

        length_guide = {
            "short": "100-200 karakter",
            "medium": "300-600 karakter",
            "long": "800-1500 karakter",
            "epic": "2000-4000 karakter (X Premium iÃ§in)"
        }

        style_guide = {
            "professional": "Profesyonel ve bilgili, otorite sahibi",
            "casual": "Samimi ve rahat, arkadaÅŸÃ§a",
            "provocative": "KÄ±ÅŸkÄ±rtÄ±cÄ± ve dÃ¼ÅŸÃ¼ndÃ¼rÃ¼cÃ¼, status quo'yu sorgulayan",
            "storytelling": "Hikaye anlatÄ±cÄ±, duygusal baÄŸ kuran",
            "educational": "Ã–ÄŸretici, deÄŸer veren, framework sunan"
        }

        tone_guide = {
            "engaging": "Dikkat Ã§ekici ve etkileÅŸim odaklÄ±",
            "controversial": "TartÄ±ÅŸmalÄ± ve cesur, karÅŸÄ±t gÃ¶rÃ¼ÅŸ",
            "inspirational": "Ä°lham verici ve motive edici",
            "humorous": "Esprili ve eÄŸlenceli",
            "raw": "Ham, dÃ¼rÃ¼st, filtresiz"
        }

        prompt = f"""Sen bir X (Twitter) iÃ§erik uzmanÄ±sÄ±n. X'in aÃ§Ä±k kaynak algoritmasÄ±nÄ± (github.com/xai-org/x-algorithm) derinlemesine biliyorsun.

GÃ–REV: AÅŸaÄŸÄ±daki kriterlere gÃ¶re viral potansiyeli yÃ¼ksek bir tweet yaz.

KONU: {topic}

STÄ°L: {style} - {style_guide.get(style, style)}
TON: {tone} - {tone_guide.get(tone, tone)}
UZUNLUK: {length_guide.get(length, length)}
{profile_strategy}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
X ALGORÄ°TMASI - KRÄ°TÄ°K BÄ°LGÄ°LER
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ENGAGEMENT AÄžIRLIKLARI (yÃ¼ksekten dÃ¼ÅŸÃ¼ÄŸe):
1. Reply (yanÄ±t) â†’ EN YÃœKSEK deÄŸer (+1.5x)
2. Repost/Retweet â†’ YÃ¼ksek deÄŸer (+2.0x)
3. Quote Tweet â†’ Ã‡ok yÃ¼ksek (+2.5x)
4. Bookmark â†’ Kalite sinyali (+0.5x)
5. Like â†’ Temel sinyal (+1.0x)

NEGATÄ°F SÄ°NYALLER (KESÄ°NLÄ°KLE KAÃ‡IN):
- DÄ±ÅŸ link â†’ Algoritma CEZALANDIRIR (-30% reach)
- 3+ hashtag â†’ Spam gibi gÃ¶rÃ¼nÃ¼r (-20%)
- "Follow for follow", "like4like" â†’ Spam tespiti (-50%)
- TamamÄ± bÃ¼yÃ¼k harf â†’ Agresif gÃ¶rÃ¼nÃ¼m (-15%)

POZÄ°TÄ°F SÄ°NYALLER (MUTLAKA KULLAN):
- SatÄ±r aralarÄ± â†’ Okunabilirlik, dwell time artÄ±rÄ±r (+10%)
- Soru sormak â†’ Reply tetikler (+30%)
- Call to action â†’ EtkileÅŸim teÅŸviki (+20%)
- Thread formatÄ± (ðŸ§µ) â†’ YÃ¼ksek engagement (+35%)
- KiÅŸisel hikaye â†’ Duygusal baÄŸ (+25%)
- TartÄ±ÅŸmalÄ± gÃ¶rÃ¼ÅŸ â†’ Engagement patlamasÄ± (+40%)

DWELL TIME OPTÄ°MÄ°ZASYONU (EN KRÄ°TÄ°K FAKTÃ–R):
Dwell time = kullanÄ±cÄ±nÄ±n tweet'te geÃ§irdiÄŸi sÃ¼re.
âš ï¸ 3 SANÄ°YEDEN AZ OKUMA = NEGATÄ°F SÄ°NYAL
Bu negatif sinyal "quality multiplier"Ä± %15-20 dÃ¼ÅŸÃ¼rÃ¼r!

DWELL TIME ARTIRMA TAKTÄ°KLERÄ°:
- Uzun, deÄŸerli iÃ§erik â†’ Daha fazla okuma sÃ¼resi
- Merak uyandÄ±ran aÃ§Ä±lÄ±ÅŸ â†’ "Scroll pass" engellenir
- Liste/madde formatÄ± â†’ Taranabilir, daha uzun kalÄ±ÅŸ
- Hikaye anlatÄ±mÄ± â†’ Sonunu merak ettir, okumaya devam
- "Plot twist" veya sÃ¼rpriz â†’ Dikkat tutar
- Paragraflar arasÄ± boÅŸluk â†’ GÃ¶z dinlenir, devam eder
- Soru sormak â†’ DÃ¼ÅŸÃ¼nme sÃ¼resi = extra dwell time
- KarÅŸÄ±tlÄ±k/Ã‡eliÅŸki â†’ "ama", "ancak", "fakat" kullan

GÄ°ZLÄ° BÄ°LGÄ° - SHADOW HIERARCHY:
- Yeni hesaplar -128 TweetCred skoruyla baÅŸlar
- Minimum +17'ye ulaÅŸmadan eriÅŸim neredeyse sÄ±fÄ±r
- Ä°lk 100 post'ta %0.5'ten dÃ¼ÅŸÃ¼k like/impression = "engagement debt"
- Engagement debt = postlar sadece %10 daÄŸÄ±tÄ±ma girer
- Grok her postu pozitif/negatif diye deÄŸerlendiriyor

MENTION STRATEJÄ°SÄ° (PARA KAZANMA Ä°Ã‡Ä°N KRÄ°TÄ°K):
- Ä°nsanlarÄ± mention'lara Ã§ek
- Mention okuyanlar reklamÄ± gÃ¶rÃ¼r
- Reklam gelirinin %30-50'si sana gelir
- TartÄ±ÅŸma baÅŸlat â†’ mention trafiÄŸi artar

OPTÄ°MAL TWEET YAPISI:
1. HOOK: Ä°lk cÃ¼mle dikkat Ã§ekici (scroll durdurucu) - DWELL TIME BAÅžLAR
2. MERAK: Ä°kinci kÄ±sÄ±m merak uyandÄ±rmalÄ± - OKUMAYA DEVAM
3. DEÄžER: Okuyucuya somut fayda saÄŸla - DWELL TIME UZAR
4. FORMAT: SatÄ±r aralarÄ± ile okunabilir - GÃ–Z YORULMAZ
5. CTA: Sonunda aksiyon Ã§aÄŸrÄ±sÄ± - MENTION'A Ã‡EK

{"CALL TO ACTION: Sonunda soru sor veya aksiyon iste (Ã¶rn: 'Ne dÃ¼ÅŸÃ¼nÃ¼yorsunuz?', 'Kaydet', 'Yorumda paylaÅŸ')" if include_cta else "Call to action EKLEME"}
{"EMOJI: Uygun yerlerde 1-3 emoji kullan (abartma, spam gÃ¶rÃ¼nÃ¼r)" if include_emoji else "EMOJI KULLANMA"}

{f"EK TALÄ°MATLAR: {custom_instructions}" if custom_instructions else ""}

Ã–NEMLÄ° KURALLAR:
1. Hashtag KULLANMA
2. Link EKLEME
3. "Bu tweet'i beÄŸen" gibi spam ifadeler KULLANMA
4. Ã–zgÃ¼n ol, ÅŸablon gibi gÃ¶rÃ¼nme
5. Ä°nsanlarÄ±n paylaÅŸmak isteyeceÄŸi deÄŸer sun

ðŸŒ DÄ°L: {lang_instruction}

Sadece tweet metnini yaz, baÅŸka aÃ§Ä±klama ekleme."""

        # UzunluÄŸa gÃ¶re max_tokens ayarla
        max_tokens_map = {
            "short": 1000,
            "medium": 2000,
            "long": 4000,
            "epic": 8000  # 4000 karakter iÃ§in ~8000 token gerekebilir
        }
        tokens = max_tokens_map.get(length, 2000)

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=tokens,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return message.content[0].text.strip()
        except Exception as e:
            return f"Hata: {str(e)}"

    def generate_thread(
        self,
        topic: str,
        num_tweets: int = 5,
        style: str = "educational",
        language: str = "tr"
    ) -> List[str]:
        """
        Claude AI ile thread Ã¼retir.

        Args:
            topic: Thread konusu
            num_tweets: Tweet sayÄ±sÄ±
            style: Stil
            language: Dil kodu (tr, en, de, fr, es, ar, zh, ja, ko, pt, ru)

        Returns:
            Tweet listesi
        """
        if not self.client:
            return ["Claude API baÄŸlantÄ±sÄ± yok. ANTHROPIC_API_KEY ayarlayÄ±n."]

        # Dil ayarlarÄ±
        language_names = {
            "tr": "TÃ¼rkÃ§e", "en": "English", "de": "Deutsch", "fr": "FranÃ§ais",
            "es": "EspaÃ±ol", "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "zh": "ä¸­æ–‡", "ja": "æ—¥æœ¬èªž",
            "ko": "í•œêµ­ì–´", "pt": "PortuguÃªs", "ru": "Ð ÑƒÑÑÐºÐ¸Ð¹"
        }
        lang_name = language_names.get(language, "TÃ¼rkÃ§e")

        prompt = f"""Sen bir X (Twitter) thread uzmanÄ±sÄ±n.

GÃ–REV: "{topic}" konusunda {num_tweets} tweet'lik viral bir thread yaz.

THREAD KURALLARI:
1. Ä°lk tweet: GÃ¼Ã§lÃ¼ hook, merak uyandÄ±rÄ±cÄ± (ðŸ§µ ile baÅŸla)
2. Orta tweetler: Her biri deÄŸer veren, baÄŸÄ±msÄ±z okunabilir
3. Son tweet: Ã–zet + call to action

HER TWEET Ä°Ã‡Ä°N:
- 200-400 karakter arasÄ±
- SatÄ±r aralarÄ± kullan
- Emoji kullan ama abartma
- Hashtag KULLANMA
- Link EKLEME

STÄ°L: {style}

ðŸŒ DÄ°L: Thread'i {lang_name} dilinde yaz.

FORMAT: Her tweet'i "---" ile ayÄ±r.

Sadece thread'i yaz, aÃ§Ä±klama ekleme."""

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=4000,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )

            response = message.content[0].text.strip()
            tweets = [t.strip() for t in response.split("---") if t.strip()]
            return tweets
        except Exception as e:
            return [f"Hata: {str(e)}"]

    def rewrite_tweet(self, original: str, style: str = "viral", language: str = "tr") -> str:
        """
        Mevcut tweet'i daha viral hale getirir.

        Args:
            original: Orijinal tweet
            style: Hedef stil (viral, controversial, emotional, educational)
            language: Dil kodu (tr, en, de, fr, es, ar, zh, ja, ko, pt, ru)

        Returns:
            Yeniden yazÄ±lmÄ±ÅŸ tweet
        """
        if not self.client:
            return "Claude API baÄŸlantÄ±sÄ± yok."

        # Dil ayarlarÄ±
        language_names = {
            "tr": "TÃ¼rkÃ§e", "en": "English", "de": "Deutsch", "fr": "FranÃ§ais",
            "es": "EspaÃ±ol", "ar": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "zh": "ä¸­æ–‡", "ja": "æ—¥æœ¬èªž",
            "ko": "í•œêµ­ì–´", "pt": "PortuguÃªs", "ru": "Ð ÑƒÑÑÐºÐ¸Ð¹"
        }
        lang_name = language_names.get(language, "TÃ¼rkÃ§e")

        prompt = f"""Sen bir X iÃ§erik editÃ¶rÃ¼sÃ¼n.

ORÄ°JÄ°NAL TWEET:
{original}

GÃ–REV: Bu tweet'i {style} tarzÄ±nda yeniden yaz.

KURALLAR:
- Ana mesajÄ± koru
- Daha dikkat Ã§ekici hale getir
- SatÄ±r aralarÄ± ekle
- Hook gÃ¼Ã§lendir
- Call to action ekle
- Hashtag ve link EKLEME
- KliÅŸe ifadeler KULLANMA

ðŸŒ DÄ°L: Tweet'i {lang_name} dilinde yaz.

Sadece yeni tweet'i yaz."""

        # Orijinal iÃ§erik uzunluÄŸuna gÃ¶re max_tokens ayarla
        original_len = len(original)
        if original_len > 2000:
            tokens = 8000
        elif original_len > 1000:
            tokens = 4000
        else:
            tokens = 2000

        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=tokens,
                messages=[
                    {"role": "user", "content": prompt}
                ]
            )
            return message.content[0].text.strip()
        except Exception as e:
            return f"Hata: {str(e)}"

    def generate_from_template(self, template_name: str, variables: Dict[str, str]) -> str:
        """Åžablondan tweet oluÅŸturur."""
        template = next((t for t in self.templates if t.name == template_name), None)
        if not template:
            raise ValueError(f"Åžablon bulunamadÄ±: {template_name}")

        tweet = template.template
        for key, value in variables.items():
            tweet = tweet.replace("{" + key + "}", value)

        return tweet

    def optimize_tweet(self, tweet: str) -> str:
        """Tweet'i algoritma iÃ§in optimize eder."""
        optimized = tweet

        # DÄ±ÅŸ linkleri kaldÄ±r
        external_links = re.findall(r'https?://(?!twitter\.com|x\.com)\S+', optimized)
        if external_links:
            for link in external_links:
                optimized = optimized.replace(link, "[link yorumda]")

        # Ã‡ok fazla hashtag varsa azalt
        hashtags = re.findall(r'#\w+', optimized)
        if len(hashtags) > 2:
            for hashtag in hashtags[2:]:
                optimized = optimized.replace(hashtag, "")

        # CTA yoksa ekle
        if "?" not in optimized and "ðŸ‘‡" not in optimized:
            cta_options = [
                "\n\nNe dÃ¼ÅŸÃ¼nÃ¼yorsunuz? ðŸ‘‡",
                "\n\nKatÄ±lÄ±yor musunuz?",
                "\n\nDeneyimlerinizi paylaÅŸÄ±n ðŸ’¬",
                "\n\nBu post'u kaydet ðŸ”–"
            ]
            optimized += random.choice(cta_options)

        # Fazla boÅŸluklarÄ± temizle
        optimized = re.sub(r'\n{3,}', '\n\n', optimized)
        optimized = re.sub(r' {2,}', ' ', optimized)

        return optimized.strip()

    def suggest_improvements(self, topic: str, style: str = "professional") -> List[str]:
        """Konu iÃ§in tweet Ã¶nerileri sunar (AI destekli veya ÅŸablon)."""

        # AI varsa AI kullan
        if self.client:
            suggestions = []
            styles = ["professional", "casual", "provocative"]
            for s in styles[:3]:
                tweet = self.generate_with_ai(topic, style=s, length="medium")
                suggestions.append(tweet)
            return suggestions

        # AI yoksa ÅŸablon bazlÄ± Ã¶neriler
        suggestions = []
        if style == "professional":
            suggestions.append(f"ðŸ§µ {topic} hakkÄ±nda kimsenin anlatmadÄ±ÄŸÄ± gerÃ§ekler:\n\nYÄ±llardÄ±r bu alanda Ã§alÄ±ÅŸÄ±yorum.\n\nBaÅŸlÄ±yoruz ðŸ‘‡")
            suggestions.append(f"{topic} konusunda en sÄ±k yapÄ±lan 3 hata:\n\n1. [hata1]\n2. [hata2]\n3. [hata3]\n\nKaÃ§Ä±ncÄ±yÄ± yapÄ±yorsunuz?")
            suggestions.append(f"Son 5 yÄ±lda {topic} ile Ã¶ÄŸrendiÄŸim en deÄŸerli ders:\n\n[ders]\n\nBu tek ÅŸey her ÅŸeyi deÄŸiÅŸtirdi.")
        elif style == "casual":
            suggestions.append(f"{topic} hakkÄ±nda garip bir ÅŸey fark ettim ðŸ‘€\n\n[gÃ¶zlem]\n\nSadece ben mi bÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorum?")
            suggestions.append(f"DÃ¼n {topic} ile ilgili bir ÅŸey denedim.\n\nSonuÃ§?\n\n[sonuÃ§]\n\nMind = blown ðŸ¤¯")
        elif style == "provocative":
            suggestions.append(f"Herkes {topic} hakkÄ±nda yanÄ±lÄ±yor.\n\nPopÃ¼ler gÃ¶rÃ¼ÅŸ: [gÃ¶rÃ¼ÅŸ]\n\nGerÃ§ek: [gerÃ§ek]\n\nFight me.")
            suggestions.append(f"{topic} endÃ¼strisi sizi kandÄ±rÄ±yor.\n\nÄ°ÅŸte kimsenin sÃ¶ylemediÄŸi gerÃ§ek:\n\n[gerÃ§ek]")

        return suggestions

    def get_best_posting_times(self) -> Dict[str, List[str]]:
        """En iyi paylaÅŸÄ±m zamanlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r."""
        return {
            "weekdays": ["08:00-09:00", "12:00-13:00", "17:00-18:00", "21:00-22:00"],
            "weekends": ["10:00-11:00", "14:00-15:00", "20:00-21:00"],
            "best_days": ["SalÄ±", "Ã‡arÅŸamba", "PerÅŸembe"],
            "avoid": ["Cuma gece", "Pazar sabah erken"],
            "peak_engagement": ["SalÄ± 10:00", "Ã‡arÅŸamba 12:00", "PerÅŸembe 17:00"]
        }

    def list_templates(self, category: Optional[str] = None) -> List[Dict]:
        """ÅžablonlarÄ± listeler."""
        templates = self.templates
        if category:
            templates = [t for t in templates if t.category == category]

        return [
            {
                "name": t.name,
                "description": t.description,
                "template": t.template,
                "engagement_boost": f"+{(t.engagement_boost - 1) * 100:.0f}%",
                "category": t.category
            }
            for t in templates
        ]

    def get_template_categories(self) -> List[str]:
        """Mevcut ÅŸablon kategorilerini dÃ¶ndÃ¼rÃ¼r."""
        return list(set(t.category for t in self.templates))


def main():
    """CLI arayÃ¼zÃ¼"""
    import argparse
    import sys

    # Windows UTF-8 encoding fix
    if sys.platform == "win32":
        sys.stdout.reconfigure(encoding='utf-8')

    parser = argparse.ArgumentParser(
        description="X Algorithm-Based Tweet Generator (AI-Powered)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ã–rnekler:
  python tweet_generator.py analyze "Tweet metniniz"
  python tweet_generator.py generate "yapay zeka" --style provocative --length long
  python tweet_generator.py thread "startup dersleri" --count 7
  python tweet_generator.py rewrite "eski tweet" --style viral
  python tweet_generator.py templates --category thread
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="Komutlar")

    # Analyze
    analyze_parser = subparsers.add_parser("analyze", help="Tweet analizi")
    analyze_parser.add_argument("tweet", help="Tweet metni")

    # Generate (AI)
    gen_parser = subparsers.add_parser("generate", help="AI ile tweet Ã¼ret")
    gen_parser.add_argument("topic", help="Konu")
    gen_parser.add_argument("--style", default="professional",
                           choices=["professional", "casual", "provocative", "storytelling", "educational"])
    gen_parser.add_argument("--tone", default="engaging",
                           choices=["engaging", "controversial", "inspirational", "humorous", "raw"])
    gen_parser.add_argument("--length", default="medium",
                           choices=["short", "medium", "long", "epic"])

    # Thread (AI)
    thread_parser = subparsers.add_parser("thread", help="AI ile thread Ã¼ret")
    thread_parser.add_argument("topic", help="Konu")
    thread_parser.add_argument("--count", type=int, default=5, help="Tweet sayÄ±sÄ±")
    thread_parser.add_argument("--style", default="educational")

    # Rewrite (AI)
    rewrite_parser = subparsers.add_parser("rewrite", help="Tweet'i yeniden yaz")
    rewrite_parser.add_argument("tweet", help="Orijinal tweet")
    rewrite_parser.add_argument("--style", default="viral",
                               choices=["viral", "controversial", "emotional", "educational"])

    # Templates
    templates_parser = subparsers.add_parser("templates", help="ÅžablonlarÄ± listele")
    templates_parser.add_argument("--category", help="Kategori filtresi")

    # Optimize
    opt_parser = subparsers.add_parser("optimize", help="Tweet optimize et")
    opt_parser.add_argument("tweet", help="Tweet metni")

    # Times
    subparsers.add_parser("times", help="En iyi paylaÅŸÄ±m zamanlarÄ±")

    args = parser.parse_args()
    generator = XAlgorithmTweetGenerator()

    if args.command == "analyze":
        analysis = generator.analyze_tweet(args.tweet)
        print("\n" + "="*50)
        print("ðŸ“Š TWEET ANALÄ°ZÄ°")
        print("="*50)
        print(f"\nðŸŽ¯ Algoritma Skoru: {analysis.score}/100")
        if analysis.strengths:
            print("\nâœ… GÃ¼Ã§lÃ¼ YÃ¶nler:")
            for s in analysis.strengths:
                print(f"   â€¢ {s}")
        if analysis.weaknesses:
            print("\nâŒ ZayÄ±f YÃ¶nler:")
            for w in analysis.weaknesses:
                print(f"   â€¢ {w}")
        if analysis.suggestions:
            print("\nðŸ’¡ Ã–neriler:")
            for s in analysis.suggestions:
                print(f"   â€¢ {s}")

    elif args.command == "generate":
        print("\nðŸ¤– AI tweet Ã¼retiyor...\n")
        tweet = generator.generate_with_ai(
            args.topic,
            style=args.style,
            tone=args.tone,
            length=args.length
        )
        print("="*50)
        print(tweet)
        print("="*50)
        print(f"\nðŸ“ {len(tweet)} karakter")

    elif args.command == "thread":
        print(f"\nðŸ§µ {args.count} tweet'lik thread Ã¼retiliyor...\n")
        tweets = generator.generate_thread(args.topic, args.count, args.style)
        for i, tweet in enumerate(tweets, 1):
            print(f"\n--- Tweet {i}/{len(tweets)} ---")
            print(tweet)

    elif args.command == "rewrite":
        print("\nâœ¨ Tweet yeniden yazÄ±lÄ±yor...\n")
        new_tweet = generator.rewrite_tweet(args.tweet, args.style)
        print("ORÄ°JÄ°NAL:")
        print(args.tweet)
        print("\nYENÄ° VERSÄ°YON:")
        print(new_tweet)

    elif args.command == "templates":
        templates = generator.list_templates(args.category)
        print("\nðŸ“ ÅžABLONLAR")
        print("="*50)
        for t in templates:
            print(f"\nðŸ”¹ {t['name']} ({t['engagement_boost']}) [{t['category']}]")
            print(f"   {t['description']}")

    elif args.command == "optimize":
        optimized = generator.optimize_tweet(args.tweet)
        print("\nâœ¨ OPTÄ°MÄ°ZE EDÄ°LMÄ°Åž:")
        print(optimized)

    elif args.command == "times":
        times = generator.get_best_posting_times()
        print("\nâ° EN Ä°YÄ° ZAMANLAR")
        print(f"Hafta iÃ§i: {', '.join(times['weekdays'])}")
        print(f"Hafta sonu: {', '.join(times['weekends'])}")
        print(f"En iyi gÃ¼nler: {', '.join(times['best_days'])}")
        print(f"Peak: {', '.join(times['peak_engagement'])}")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
